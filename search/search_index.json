{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RRA Tools","text":"<p>Documentation: https://ihmeuw.github.io/rra-tools</p> <p>Source Code: https://github.com/ihmeuw/rra-tools</p> <p>PyPI: https://pypi.org/project/rra-tools/</p> <p>Common utilities for IHME Rapid Response team pipelines.</p>"},{"location":"#cli-tools","title":"CLI Tools","text":"<p>The provided cli tools break down into three categories.</p>"},{"location":"#exception-handling","title":"Exception handling","text":"<p>The <code>cli_tools</code> subpackage provides a <code>handle_exceptions</code> wrapper that can be used to wrap functions that may raise exceptions and drop into a pdb shell when an exception is raised. This is useful for debugging functions that are failing in a pipeline.</p> <pre><code>from rra_tools.cli_tools import handle_exceptions\nfrom loguru import logger\n\ndef my_task():\n    ...\n\n\nif __name__ == \"__main__\":\n    runner = handle_exceptions(my_task, logger, with_debugger=True)\n    runner()\n</code></pre>"},{"location":"#dynamic-module-import","title":"Dynamic module import","text":"<p>The <code>cli_tools</code> subpackage provides a <code>load_module_from_info</code> function that can be used to dynamically import a module. This is a useful pattern for creating a CLI that can dynamically add new commands and subcommands based on subpackage structure.</p> <p>TODO: Usage example</p>"},{"location":"#click-options","title":"Click options","text":"<p>The <code>cli_tools</code> subpackage provides several click options that can be used to create CLI commands with common options.</p> <ul> <li><code>with_verbose</code> - Add a <code>--verbose</code>, <code>-v</code> option to the command to increase the log     verbosity</li> <li><code>with_debugger</code> - Add a <code>--pdb</code> option to the command to drop into a pdb shell on     exception</li> <li><code>with_input_directory</code> - Add a parameterizeable <code>--{dir-name}-dir</code> option to the     command to specify an input directory.</li> <li><code>with_output_directory</code> - Add a <code>--output-dir</code>, <code>-o</code> option to the command to     specify an output directory.</li> <li><code>with_num_cores</code> - Add a <code>--num-cores</code>, <code>-c</code> option to the command to specify the     number of cores to use for parallel processing.</li> <li><code>with_queue</code> - Add a <code>--queue</code>, <code>-q</code> option to the command to specify a slurm queue     to run jobs on.</li> <li><code>with_progress_bar</code> - Add a <code>--progress-bar</code>, <code>--pb</code> option to the command to     display a progress bar for long-running tasks.</li> <li><code>with_dry_run</code> - Add a <code>--dry-run</code>, <code>-n</code> option to the command to run the command     without actually executing the task.</li> </ul> <p>These options do not provide implementations for the options, but rather provide a standard interface for adding these options to a command to ensure consistency across commands. Several of these options are meant to be used with other tools provided in this package like exception handling, logging, and parallel processing.</p> <pre><code>import click\nfrom loguru import logger\n\nfrom rra_tools.cli_tools import (\n    with_verbose,\n    with_debugger,\n    with_output_directory,\n    handle_exceptions,\n)\nfrom rra_tools.logging import configure_logging_to_terminal\n\ndef my_task_main(output_dir: str):\n    ...\n\n\n@click.command()\n@with_output_directory(\"/path/to/default/output\")\n@with_verbose()\n@with_debugger()\ndef my_task(output_dir: str, verbose: int, debugger: bool):\n    configure_logging_to_terminal(verbose)\n    runner = handle_exceptions(my_task_main, logger, with_debugger=debugger)\n    runner(output_dir)\n</code></pre>"},{"location":"#logging","title":"Logging","text":"<p>The <code>logging</code> subpackage provides a number of utilities for configuring loggers and for performance logging. This package is built on top of the <code>loguru</code> package, which provides a more flexible and powerful logging interface than the standard library <code>logging</code> package.</p>"},{"location":"#configuration","title":"Configuration","text":"<p>There are three main functions for configuring loggers:</p> <ul> <li><code>configure_logging_to_terminal</code> - Configure a logger to log to the terminal</li> <li><code>configure_logging_to_file</code> - Configure a logger to log to a file</li> <li><code>add_logging_sink</code> - A generic function to add a sink to a logger</li> </ul> <p>The first two options are convenience functions that set up a logger with a standard configuration. The third option is more flexible and can be used to add additional sinks to a logger.</p>"},{"location":"#performance-logging","title":"Performance Logging","text":"<p>The <code>logging</code> subpackage provides a <code>task_performance_logger</code> that is a drop-in replacement for the <code>loguru</code> logger that logs the time taken to run a task.</p> <pre><code>from rra_tools.logging import task_performance_logger as logger\n\ndef my_task():\n    logger.debug(\"Loading training data\", context=\"load_data\")\n    # Load the data\n\n    logger.debug(\"Training model\", context=\"train_model\")\n    # Train the model\n\n    # Using the same context for logging will accumulate time\n    # spent in that context across both usages.\n    logger.debub(\"Loading inference_data\", context=\"load_data\")\n    # Load the inference data\n\n    logger.debug(\"Evaluating model\", context=\"evaluate_model\")\n    # Evaluate the model\n\n    logger.debug(\"Saving results\", context=\"save_results\")\n    # Save the results\n\n    logger.report()  # Prints out the time spent in each logging context\n</code></pre> <p>Additionally, <code>rra_tools</code> provides a command line tool <code>parse_logs</code> that can be used to summarize the performance logs generated by the <code>task_performance_logger</code>. This is useful when trying to understand the runtime characteristics of a pipeline that may run hundreds or thousands of tasks.</p> <pre><code>parse_logs path/to/output/log/directory/\n</code></pre>"},{"location":"#shell-tools","title":"Shell Tools","text":"<p>The <code>shell_tools</code> module provides a few functions to run common shell commands.</p> <ol> <li><code>wget</code> - Download a file from a URL</li> </ol> <p>```python     from rra_tools.shell_tools import wget</p> <pre><code>wget(\"https://example.com/file.txt\", \"path/to/output.txt\")\n```\n</code></pre> <ol> <li><code>unzip_and_delete_archive</code> - Unzip a file and delete the archive</li> </ol> <p>```python     from rra_tools.shell_tools import unzip_and_delete_archive</p> <pre><code>unzip_and_delete_archive(\"path/to/archive.zip\", \"path/to/output\")\n```\n\nNote: you may need to install `unzip` on your system to use this function. You\ncan do so with `conda install -c conda-forge unzip`.\n</code></pre> <ol> <li> <p><code>mkdir</code> - Create a directory with correct permissions.     The default operation of mkdir via the <code>os</code> module or <code>pathlib</code> translates uses     the umask of the user running the script along with the permissions set. This     often results in unexpected permissions on the created directory. This function     allows you to specify the permissions of the directory without relying on the     umask.</p> <pre><code>from rra_tools.shell_tools import mkdir\n\nmkdir(\"path/to/directory\", mode=0o755)\n# Can also make parents\nmkdir(\"path/to/other/directory\", parents=True, mode=0o775)\n# Can also do a no-op if the directory already exists\nmkdir(\"path/to/other/directory\", mode=0o775)\n</code></pre> </li> <li> <p><code>touch</code> - Create a file with the correct permissions.     Like <code>mkdir</code>, <code>touch</code> allows you to specify the permissions of the file without     relying on the umask.</p> <pre><code>from rra_tools.shell_tools import touch\n\ntouch(\"path/to/file.txt\", mode=0o664)\n</code></pre> </li> </ol>"},{"location":"#parallel-processing-with-multiprocessing","title":"Parallel Processing with Multiprocessing","text":"<p>The <code>parallel</code> module provides a utility to run a function of a single argument in parallel across a list of inputs using multiprocessing.</p> <pre><code>from rra_tools.parallel import run_parallel\n\n# Trivial example\ndef my_runner(x):\n    return x ** 2\n\ninputs = list(range(1000))\n\nresults = run_parallel(\n    my_runner,\n    inputs,\n    num_cores=3,  # By default, num_cores is set to 1 and will run sequentially\n)\n</code></pre> <p>In practice, the function we want to parallelize will be significantly more complex than the trivial example above. Generally, you want to set things up so that:</p> <ol> <li>The function you want to parallelize is self-contained and does not rely on any     global state.</li> <li>The function you want to parallelize is relatively expensive to run. If the     function is cheap to run, the overhead of parallelization can outweigh the benefits     of parallelization.</li> <li>The input argument to the function is relatively small in memory. Multiprocessing     needs to copy the input data to each worker process, so if the input data is large,     the overhead of copying the data can outweigh the benefits of parallelization.     A common way to overcome this limitation is to pass the path to the input data     instead of the data itself and then have the function read the data from the path.</li> <li>The function is not too complex. If your <code>runner</code> function is complicated, you may     end up with resource contention between the worker processes that is hard to     understand (e.g. you may run out of memory because each worker process is trying     is loading a big dataset at the same time). There's no hard and fast rule here,     but once functions get to be more than a few dozen lines long, you should start     thinking about whether process-based parallelization is the right choice, and maybe     opt for a different parallelization strategy (like <code>jobmon</code> described below).</li> </ol>"},{"location":"#jobmon-integration","title":"Jobmon Integration","text":"<p>The <code>jobmon</code> module provides a set of utilities to run more complicated parallel jobs by interfacing with a job scheduler like <code>slurm</code>. See Jobmon documentation for more information.</p>"},{"location":"#installation","title":"Installation","text":"<p>Jobmon is not installed by default with <code>rra-tools</code> and is only available to download and install on the IHME cluster. To install jobmon, you must have a conf file in your home directory at <code>~/.pip/pip.conf</code> with the following contents:</p> <pre><code>[global]\nextra-index-url = https://artifactory.ihme.washington.edu/artifactory/api/pypi/pypi-shared/simple\ntrusted-host = artifactory.ihme.washington.edu/artifactory/api/pypi/pypi-shared\n</code></pre> <p>Then you can install jobmon with:</p> <pre><code>pip install jobmon[ihme]\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>TBD</p>"},{"location":"#translation","title":"Translation","text":"<p>The <code>translate</code> module provides functions to translate text files from one language to another.</p> <pre><code>from rra_tools.translate import translate_text_file\n\ntranslate_text_file(\"path/to/input.txt\", \"path/to/output.txt\")\n</code></pre> <p>By default, it will attempt to autodetect the language in the input file and produce outputs in English, but you can specify the source and target languages:</p> <pre><code>from rra_tools.translate import translate_text_file\n# Translate from German to Spanish\ntranslate_text_file(\n    \"path/to/input.txt\",\n    \"path/to/output.txt\",\n    source_language=\"de\",\n    target_language=\"es\",\n)\n</code></pre> <p>The <code>translate</code> subpackage can also translate dataframe columns</p> <pre><code>import pandas as pd\nfrom rra_tools.translate import translate_dataframe\n\ndf = pd.DataFrame({\"text\": [\"hola\", \"mundo\"]})\ntranslated_df = translate_dataframe(df, columns=[\"text\"])\n</code></pre>"},{"location":"#installation_1","title":"Installation","text":"<pre><code>pip install rra-tools\n</code></pre>"},{"location":"#development","title":"Development","text":"<p>Instructions using conda:</p> <ol> <li> <p>Clone this repository.</p> <p>Over ssh: <pre><code>git clone git@github.com:ihmeuw/climate-downscale.git\n</code></pre></p> <p>Over https: <pre><code>git clone https://github.com/ihmeuw/climate-downscale.git\n</code></pre></p> </li> <li> <p>Create a new conda environment.</p> <pre><code>conda create -n climate-downscale python=3.10\nconda activate climate-downscale\n</code></pre> </li> <li> <p>Install <code>poetry</code> and the project dependencies.</p> <pre><code>conda install poetry\npoetry install\n</code></pre> </li> </ol>"},{"location":"#documentation","title":"Documentation","text":"<p>The documentation is automatically generated from the content of the <code>docs</code> directory and from the docstrings  of the public signatures of the source code. The documentation is updated and published as a Github project page   automatically as part each release.</p>"},{"location":"#releasing","title":"Releasing","text":"<p>Trigger the Draft release workflow (press Run workflow). This will update the changelog &amp; version and create a GitHub release which is in Draft state.</p> <p>Find the draft release from the GitHub releases and publish it. When  a release is published, it'll trigger release workflow which creates PyPI  release and deploys updated documentation.</p>"},{"location":"#pre-commit","title":"Pre-commit","text":"<p>Pre-commit hooks run all the auto-formatting (<code>ruff format</code>), linters (e.g. <code>ruff</code> and <code>mypy</code>), and other quality  checks to make sure the changeset is in good shape before a commit/push happens.</p> <p>You can install the hooks with (runs for each commit):</p> <pre><code>pre-commit install\n</code></pre> <p>Or if you want them to run only for each push:</p> <pre><code>pre-commit install -t pre-push\n</code></pre> <p>Or if you want e.g. want to run all checks manually for all files:</p> <pre><code>poetry run pre-commit run --all-files\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#1025-2025-02-26","title":"1.0.25 - 2025-02-26","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Build chain and dependency updates to move to poetry v2.</li> </ul>"},{"location":"changelog/#1024-2025-02-26","title":"1.0.24 - 2025-02-26","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Better type annotation for click options</li> <li>Unpinned lib dependencies so downstream consumers can use versions of their choice.</li> <li>Fixed min python version at 3.12</li> <li>Updated error message and workflow url for jobmon 3.4.0</li> </ul>"},{"location":"changelog/#1023-2025-01-29","title":"1.0.23 - 2025-01-29","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Better logdir creation for different workflows.</li> </ul>"},{"location":"changelog/#1022-2024-12-31","title":"1.0.22 - 2024-12-31","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Handle chained callbacks in with_choice</li> </ul>"},{"location":"changelog/#1021-2024-12-31","title":"1.0.21 - 2024-12-31","text":""},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Fixed default for with_choice when convert is not set.</li> </ul>"},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Add a <code>clobber</code> argument to touch.</li> </ul>"},{"location":"changelog/#1020-2024-12-31","title":"1.0.20 - 2024-12-31","text":""},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Add convert_choice to api</li> </ul>"},{"location":"changelog/#1019-2024-12-30","title":"1.0.19 - 2024-12-30","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Plotting utility functions</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Update stdout/stderr keys for jobmon again</li> </ul>"},{"location":"changelog/#1018-2024-12-30","title":"1.0.18 - 2024-12-30","text":""},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Update stdout/stderr keys for jobmon</li> </ul>"},{"location":"changelog/#1017-2024-12-30","title":"1.0.17 - 2024-12-30","text":""},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>Add invalid choice handling to <code>convert_choice</code>.</li> </ul>"},{"location":"changelog/#1016-2024-12-30","title":"1.0.16 - 2024-12-30","text":""},{"location":"changelog/#fixed_6","title":"Fixed","text":"<ul> <li>Use <code>Collection</code> instead of <code>Sequence</code> in typing to support, e.g., dicts.</li> </ul>"},{"location":"changelog/#1015-2024-12-28","title":"1.0.15 - 2024-12-28","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Rework both parallel interfaces to have more flexible types.</li> </ul>"},{"location":"changelog/#1014-2024-12-28","title":"1.0.14 - 2024-12-28","text":""},{"location":"changelog/#fixed_7","title":"Fixed","text":"<ul> <li>Add <code>with_overwrite</code> to interface.</li> </ul>"},{"location":"changelog/#1013-2024-12-28","title":"1.0.13 - 2024-12-28","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>Automatically process choices with a <code>RUN_ALL</code> option into a list.</li> <li>Add <code>with_overwrite</code> cli option.</li> </ul>"},{"location":"changelog/#1012-2024-11-13","title":"1.0.12 - 2024-11-13","text":""},{"location":"changelog/#fixed_8","title":"Fixed","text":"<ul> <li>Return workflow status from <code>jobmon.run_parallel</code></li> </ul>"},{"location":"changelog/#1011-2024-06-25","title":"1.0.11 - 2024-06-25","text":""},{"location":"changelog/#added_7","title":"Added","text":"<ul> <li>Backwards compatibility with pandas 1.5</li> </ul>"},{"location":"changelog/#1010-2024-05-28","title":"1.0.10 - 2024-05-28","text":""},{"location":"changelog/#added_8","title":"Added","text":"<ul> <li>Change default timeout for jobmon workflow to 3 days instead of 10 hours.</li> </ul>"},{"location":"changelog/#109-2024-05-27","title":"1.0.9 - 2024-05-27","text":""},{"location":"changelog/#added_9","title":"Added","text":"<ul> <li>Add concurrency limit and max attempts to jobmon.</li> </ul>"},{"location":"changelog/#108-2024-05-22","title":"1.0.8 - 2024-05-22","text":""},{"location":"changelog/#added_10","title":"Added","text":"<ul> <li>Proper usage of jobmon node, task, and op args.</li> <li>Upgrade <code>requests</code> package to patch security vulnerability.</li> </ul>"},{"location":"changelog/#107-2024-05-15","title":"1.0.7 - 2024-05-15","text":""},{"location":"changelog/#fixed_9","title":"Fixed","text":"<ul> <li>Make output and error log subdirectories</li> </ul>"},{"location":"changelog/#106-2024-05-13","title":"1.0.6 - 2024-05-13","text":""},{"location":"changelog/#fixed_10","title":"Fixed","text":"<ul> <li>Argument formatting error for click.</li> </ul>"},{"location":"changelog/#105-2024-05-13","title":"1.0.5 - 2024-05-13","text":""},{"location":"changelog/#fixed_11","title":"Fixed","text":"<ul> <li>Add <code>RUN_ALL</code> and <code>ClickOption</code> to the <code>cli_tools</code> interface.</li> </ul>"},{"location":"changelog/#104-2024-05-13","title":"1.0.4 - 2024-05-13","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Remove <code>with_year</code> and add more generic <code>with_choice</code> option to <code>cli_tools</code> subpackage.</li> <li>Add <code>process_choice</code> and <code>with_choice</code> to the <code>cli_tools</code> interface.</li> </ul>"},{"location":"changelog/#103-2024-05-13","title":"1.0.3 - 2024-05-13","text":""},{"location":"changelog/#added_11","title":"Added","text":"<ul> <li>Add a method to process choice-type CLI options and add a <code>with_year</code> option.</li> </ul>"},{"location":"changelog/#102-2024-05-10","title":"1.0.2 - 2024-05-10","text":""},{"location":"changelog/#fixed_12","title":"Fixed","text":"<ul> <li>Extraneous output-dir arg in jobmon command template</li> </ul>"},{"location":"changelog/#101-2024-05-10","title":"1.0.1 - 2024-05-10","text":""},{"location":"changelog/#added_12","title":"Added","text":"<ul> <li>Basic import test</li> </ul>"},{"location":"changelog/#fixed_13","title":"Fixed","text":"<ul> <li>Typing of index in <code>rra_tools.parallel</code></li> </ul>"},{"location":"changelog/#100-2024-05-09","title":"1.0.0 - 2024-05-09","text":""},{"location":"changelog/#added_13","title":"Added","text":"<ul> <li>Initial repo setup</li> <li>Added translation module</li> <li>Added module with shell tools</li> <li>Added module for parallel processing with multiprocessing</li> <li>Added module for parallel processing with jobmon</li> <li>Added subpackage with cli tools</li> <li>Added subpackage with logging utilities</li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>rra_tools<ul> <li>cli_tools<ul> <li>exceptions</li> <li>importers</li> <li>options</li> </ul> </li> <li>jobmon</li> <li>logging<ul> <li>config</li> <li>performance</li> <li>protocol</li> </ul> </li> <li>parallel</li> <li>plotting</li> <li>shell_tools</li> <li>translate</li> </ul> </li> </ul>"},{"location":"reference/rra_tools/","title":"rra_tools","text":""},{"location":"reference/rra_tools/#rra_tools.cli_tools","title":"<code>cli_tools</code>","text":""},{"location":"reference/rra_tools/#rra_tools.cli_tools.convert_choice","title":"<code>convert_choice(value: str, choices: Collection[str]) -&gt; list[str]</code>","text":"<p>Convert a choice to a list of choices, handling the special 'All' choice.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.convert_choice--parameters","title":"Parameters","text":"<p>value     The choice to convert. choices     The set of choices to choose from.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.convert_choice--returns","title":"Returns","text":"<p>list[str]     The list of choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def convert_choice(value: str, choices: Collection[str]) -&gt; list[str]:\n    \"\"\"Convert a choice to a list of choices, handling the special 'All' choice.\n\n    Parameters\n    ----------\n    value\n        The choice to convert.\n    choices\n        The set of choices to choose from.\n\n    Returns\n    -------\n    list[str]\n        The list of choices.\n    \"\"\"\n    if value == RUN_ALL:\n        return list(choices)\n    elif value in choices:\n        return [value]\n    else:\n        msg = f\"Invalid choice: {value}. Must be one of {choices} or {RUN_ALL}.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.handle_exceptions","title":"<code>handle_exceptions(func: Callable[P, T], logger: SupportsLogging, *, with_debugger: bool) -&gt; Callable[P, T]</code>","text":"<p>Drops a user into an interactive debugger if func raises an error.</p> Source code in <code>src/rra_tools/cli_tools/exceptions.py</code> <pre><code>def handle_exceptions[**P, T](\n    func: Callable[P, T],\n    logger: SupportsLogging,\n    *,\n    with_debugger: bool,\n) -&gt; Callable[P, T]:\n    \"\"\"Drops a user into an interactive debugger if func raises an error.\"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; T:  # type: ignore[return]\n        try:\n            return func(*args, **kwargs)\n        except (BdbQuit, KeyboardInterrupt):\n            raise\n        except Exception:\n            msg = \"Uncaught exception\"\n            logger.exception(msg)\n            if with_debugger:\n                import pdb  # noqa: T100\n                import traceback\n\n                traceback.print_exc()\n                pdb.post_mortem()\n            else:\n                raise\n\n    return wrapped\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.import_module_from_info","title":"<code>import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType</code>","text":"<p>Import a module from a ModuleInfo object.</p> Source code in <code>src/rra_tools/cli_tools/importers.py</code> <pre><code>def import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType:\n    \"\"\"Import a module from a ModuleInfo object.\"\"\"\n    finder = module_info.module_finder\n    spec = finder.find_spec(module_info.name)  # type: ignore[call-arg]\n    module = spec.loader.load_module(module_info.name)  # type: ignore[union-attr]\n    return module  # noqa: RET504\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.process_choices","title":"<code>process_choices(allow_all: bool, choices: Collection[str] | None) -&gt; tuple[click.ParamType, str | None, bool]</code>","text":"<p>Support function for creating options with choices.</p> <p>A common pattern in RRA pipelines is to build CLIs that admit a choice of a specific set of values or a special value that represents all possible values. This function provides a way to handle this pattern in a consistent way.</p> <p>There are four possible cases: 1. No choices are provided and RUN_ALL is allowed. This is useful when the     set of choices is not known ahead of time, or is contingent on another     option. For example, if there is a task that depends on location and year,     but the years available depend on the location. The user might want to     run a single year for a location (which they'll have to know ahead of time);     or all years for a location, which would be the subset of years available     for that location; or all years for all locations, which could be a different     subset of years for each included location. 2. Choices are provided and RUN_ALL is allowed. This is useful when the set of     choices is known ahead of time, but the user might want to run all of them. 3. No choices are provided and RUN_ALL is not allowed. This is useful when the     set of choices is not known ahead of time, but the user must provide a value. 4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of     choices is known ahead of time and the user must provide a value.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.process_choices--parameters","title":"Parameters","text":"<p>allow_all     Whether to allow the special value RUN_ALL. choices     The set of choices to allow.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.process_choices--returns","title":"Returns","text":"<p>tuple[click.ParamType, str | None, bool]     The option type, default value, and whether to show the default.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def process_choices(\n    allow_all: bool,  # noqa: FBT001\n    choices: Collection[str] | None,\n) -&gt; tuple[click.ParamType, str | None, bool]:\n    \"\"\"Support function for creating options with choices.\n\n    A common pattern in RRA pipelines is to build CLIs that admit a choice\n    of a specific set of values or a special value that represents all\n    possible values. This function provides a way to handle this pattern\n    in a consistent way.\n\n    There are four possible cases:\n    1. No choices are provided and RUN_ALL is allowed. This is useful when the\n        set of choices is not known ahead of time, or is contingent on another\n        option. For example, if there is a task that depends on location and year,\n        but the years available depend on the location. The user might want to\n        run a single year for a location (which they'll have to know ahead of time);\n        or all years for a location, which would be the subset of years available\n        for that location; or all years for all locations, which could be a different\n        subset of years for each included location.\n    2. Choices are provided and RUN_ALL is allowed. This is useful when the set of\n        choices is known ahead of time, but the user might want to run all of them.\n    3. No choices are provided and RUN_ALL is not allowed. This is useful when the\n        set of choices is not known ahead of time, but the user must provide a value.\n    4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of\n        choices is known ahead of time and the user must provide a value.\n\n    Parameters\n    ----------\n    allow_all\n        Whether to allow the special value RUN_ALL.\n    choices\n        The set of choices to allow.\n\n    Returns\n    -------\n    tuple[click.ParamType, str | None, bool]\n        The option type, default value, and whether to show the default.\n    \"\"\"\n\n    if choices is None:\n        option_type: click.ParamType = click.STRING\n        default = RUN_ALL if allow_all else None\n    else:\n        choices = list(choices)\n        if allow_all:\n            choices.append(RUN_ALL)\n            default = RUN_ALL\n        else:\n            default = None\n        option_type = click.Choice(choices)\n    show_default = default is not None\n    return option_type, default, show_default\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.with_choice","title":"<code>with_choice(name: str, short_name: str | None = None, *, allow_all: bool = True, choices: Collection[str] | None = None, convert: bool | None = None, **kwargs: Any) -&gt; Callable[[Callable[P, T]], Callable[P, T]]</code>","text":"<p>Create an option with a set of choices.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.with_choice--parameters","title":"Parameters","text":"<p>name     The name of the option. short_name     An optional short name for the option. allow_all     Whether to allow the special value \"ALL\", which represents all choices. choices     The set of choices to allow. convert     Whether to convert the provided argument to a list, resolving the special     value \"ALL\" to all choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def with_choice[**P, T](\n    name: str,\n    short_name: str | None = None,\n    *,\n    allow_all: bool = True,\n    choices: Collection[str] | None = None,\n    convert: bool | None = None,\n    **kwargs: Any,\n) -&gt; Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create an option with a set of choices.\n\n    Parameters\n    ----------\n    name\n        The name of the option.\n    short_name\n        An optional short name for the option.\n    allow_all\n        Whether to allow the special value \"ALL\", which represents all choices.\n    choices\n        The set of choices to allow.\n    convert\n        Whether to convert the provided argument to a list, resolving the special\n        value \"ALL\" to all choices.\n\n    \"\"\"\n\n    names = [f\"--{name.replace('_', '-')}\"]\n    if short_name is not None:\n        if len(short_name) != 1:\n            msg = \"Short names must be a single character.\"\n            raise ValueError(msg)\n        names.append(f\"-{short_name}\")\n    option_type, default, show_default = process_choices(allow_all, choices)\n\n    if choices and convert is None:\n        convert = allow_all\n\n    if convert:\n        if not allow_all:\n            msg = \"Conversion is only supported when allow_all is True.\"\n            raise ValueError(msg)\n        if choices is None:\n            msg = \"Conversion is only supported when choices are provided.\"\n            raise ValueError(msg)\n\n        if \"callback\" in kwargs:\n            old_callback = kwargs.pop(\"callback\")\n\n            def _callback(\n                ctx: click.Context,\n                param: click.Parameter,\n                value: str,\n            ) -&gt; list[str]:\n                value = old_callback(ctx, param, value)\n                return convert_choice(value, choices)\n        else:\n\n            def _callback(\n                ctx: click.Context,  # noqa: ARG001\n                param: click.Parameter,  # noqa: ARG001\n                value: str,\n            ) -&gt; list[str]:\n                return convert_choice(value, choices)\n\n        kwargs[\"callback\"] = _callback\n\n    return click.option(\n        *names,\n        type=option_type,\n        default=default,\n        show_default=show_default,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.exceptions","title":"<code>exceptions</code>","text":""},{"location":"reference/rra_tools/#rra_tools.cli_tools.exceptions.handle_exceptions","title":"<code>handle_exceptions(func: Callable[P, T], logger: SupportsLogging, *, with_debugger: bool) -&gt; Callable[P, T]</code>","text":"<p>Drops a user into an interactive debugger if func raises an error.</p> Source code in <code>src/rra_tools/cli_tools/exceptions.py</code> <pre><code>def handle_exceptions[**P, T](\n    func: Callable[P, T],\n    logger: SupportsLogging,\n    *,\n    with_debugger: bool,\n) -&gt; Callable[P, T]:\n    \"\"\"Drops a user into an interactive debugger if func raises an error.\"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; T:  # type: ignore[return]\n        try:\n            return func(*args, **kwargs)\n        except (BdbQuit, KeyboardInterrupt):\n            raise\n        except Exception:\n            msg = \"Uncaught exception\"\n            logger.exception(msg)\n            if with_debugger:\n                import pdb  # noqa: T100\n                import traceback\n\n                traceback.print_exc()\n                pdb.post_mortem()\n            else:\n                raise\n\n    return wrapped\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.importers","title":"<code>importers</code>","text":""},{"location":"reference/rra_tools/#rra_tools.cli_tools.importers.import_module_from_info","title":"<code>import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType</code>","text":"<p>Import a module from a ModuleInfo object.</p> Source code in <code>src/rra_tools/cli_tools/importers.py</code> <pre><code>def import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType:\n    \"\"\"Import a module from a ModuleInfo object.\"\"\"\n    finder = module_info.module_finder\n    spec = finder.find_spec(module_info.name)  # type: ignore[call-arg]\n    module = spec.loader.load_module(module_info.name)  # type: ignore[union-attr]\n    return module  # noqa: RET504\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options","title":"<code>options</code>","text":""},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.convert_choice","title":"<code>convert_choice(value: str, choices: Collection[str]) -&gt; list[str]</code>","text":"<p>Convert a choice to a list of choices, handling the special 'All' choice.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.convert_choice--parameters","title":"Parameters","text":"<p>value     The choice to convert. choices     The set of choices to choose from.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.convert_choice--returns","title":"Returns","text":"<p>list[str]     The list of choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def convert_choice(value: str, choices: Collection[str]) -&gt; list[str]:\n    \"\"\"Convert a choice to a list of choices, handling the special 'All' choice.\n\n    Parameters\n    ----------\n    value\n        The choice to convert.\n    choices\n        The set of choices to choose from.\n\n    Returns\n    -------\n    list[str]\n        The list of choices.\n    \"\"\"\n    if value == RUN_ALL:\n        return list(choices)\n    elif value in choices:\n        return [value]\n    else:\n        msg = f\"Invalid choice: {value}. Must be one of {choices} or {RUN_ALL}.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.process_choices","title":"<code>process_choices(allow_all: bool, choices: Collection[str] | None) -&gt; tuple[click.ParamType, str | None, bool]</code>","text":"<p>Support function for creating options with choices.</p> <p>A common pattern in RRA pipelines is to build CLIs that admit a choice of a specific set of values or a special value that represents all possible values. This function provides a way to handle this pattern in a consistent way.</p> <p>There are four possible cases: 1. No choices are provided and RUN_ALL is allowed. This is useful when the     set of choices is not known ahead of time, or is contingent on another     option. For example, if there is a task that depends on location and year,     but the years available depend on the location. The user might want to     run a single year for a location (which they'll have to know ahead of time);     or all years for a location, which would be the subset of years available     for that location; or all years for all locations, which could be a different     subset of years for each included location. 2. Choices are provided and RUN_ALL is allowed. This is useful when the set of     choices is known ahead of time, but the user might want to run all of them. 3. No choices are provided and RUN_ALL is not allowed. This is useful when the     set of choices is not known ahead of time, but the user must provide a value. 4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of     choices is known ahead of time and the user must provide a value.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.process_choices--parameters","title":"Parameters","text":"<p>allow_all     Whether to allow the special value RUN_ALL. choices     The set of choices to allow.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.process_choices--returns","title":"Returns","text":"<p>tuple[click.ParamType, str | None, bool]     The option type, default value, and whether to show the default.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def process_choices(\n    allow_all: bool,  # noqa: FBT001\n    choices: Collection[str] | None,\n) -&gt; tuple[click.ParamType, str | None, bool]:\n    \"\"\"Support function for creating options with choices.\n\n    A common pattern in RRA pipelines is to build CLIs that admit a choice\n    of a specific set of values or a special value that represents all\n    possible values. This function provides a way to handle this pattern\n    in a consistent way.\n\n    There are four possible cases:\n    1. No choices are provided and RUN_ALL is allowed. This is useful when the\n        set of choices is not known ahead of time, or is contingent on another\n        option. For example, if there is a task that depends on location and year,\n        but the years available depend on the location. The user might want to\n        run a single year for a location (which they'll have to know ahead of time);\n        or all years for a location, which would be the subset of years available\n        for that location; or all years for all locations, which could be a different\n        subset of years for each included location.\n    2. Choices are provided and RUN_ALL is allowed. This is useful when the set of\n        choices is known ahead of time, but the user might want to run all of them.\n    3. No choices are provided and RUN_ALL is not allowed. This is useful when the\n        set of choices is not known ahead of time, but the user must provide a value.\n    4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of\n        choices is known ahead of time and the user must provide a value.\n\n    Parameters\n    ----------\n    allow_all\n        Whether to allow the special value RUN_ALL.\n    choices\n        The set of choices to allow.\n\n    Returns\n    -------\n    tuple[click.ParamType, str | None, bool]\n        The option type, default value, and whether to show the default.\n    \"\"\"\n\n    if choices is None:\n        option_type: click.ParamType = click.STRING\n        default = RUN_ALL if allow_all else None\n    else:\n        choices = list(choices)\n        if allow_all:\n            choices.append(RUN_ALL)\n            default = RUN_ALL\n        else:\n            default = None\n        option_type = click.Choice(choices)\n    show_default = default is not None\n    return option_type, default, show_default\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.with_choice","title":"<code>with_choice(name: str, short_name: str | None = None, *, allow_all: bool = True, choices: Collection[str] | None = None, convert: bool | None = None, **kwargs: Any) -&gt; Callable[[Callable[P, T]], Callable[P, T]]</code>","text":"<p>Create an option with a set of choices.</p>"},{"location":"reference/rra_tools/#rra_tools.cli_tools.options.with_choice--parameters","title":"Parameters","text":"<p>name     The name of the option. short_name     An optional short name for the option. allow_all     Whether to allow the special value \"ALL\", which represents all choices. choices     The set of choices to allow. convert     Whether to convert the provided argument to a list, resolving the special     value \"ALL\" to all choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def with_choice[**P, T](\n    name: str,\n    short_name: str | None = None,\n    *,\n    allow_all: bool = True,\n    choices: Collection[str] | None = None,\n    convert: bool | None = None,\n    **kwargs: Any,\n) -&gt; Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create an option with a set of choices.\n\n    Parameters\n    ----------\n    name\n        The name of the option.\n    short_name\n        An optional short name for the option.\n    allow_all\n        Whether to allow the special value \"ALL\", which represents all choices.\n    choices\n        The set of choices to allow.\n    convert\n        Whether to convert the provided argument to a list, resolving the special\n        value \"ALL\" to all choices.\n\n    \"\"\"\n\n    names = [f\"--{name.replace('_', '-')}\"]\n    if short_name is not None:\n        if len(short_name) != 1:\n            msg = \"Short names must be a single character.\"\n            raise ValueError(msg)\n        names.append(f\"-{short_name}\")\n    option_type, default, show_default = process_choices(allow_all, choices)\n\n    if choices and convert is None:\n        convert = allow_all\n\n    if convert:\n        if not allow_all:\n            msg = \"Conversion is only supported when allow_all is True.\"\n            raise ValueError(msg)\n        if choices is None:\n            msg = \"Conversion is only supported when choices are provided.\"\n            raise ValueError(msg)\n\n        if \"callback\" in kwargs:\n            old_callback = kwargs.pop(\"callback\")\n\n            def _callback(\n                ctx: click.Context,\n                param: click.Parameter,\n                value: str,\n            ) -&gt; list[str]:\n                value = old_callback(ctx, param, value)\n                return convert_choice(value, choices)\n        else:\n\n            def _callback(\n                ctx: click.Context,  # noqa: ARG001\n                param: click.Parameter,  # noqa: ARG001\n                value: str,\n            ) -&gt; list[str]:\n                return convert_choice(value, choices)\n\n        kwargs[\"callback\"] = _callback\n\n    return click.option(\n        *names,\n        type=option_type,\n        default=default,\n        show_default=show_default,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.jobmon","title":"<code>jobmon</code>","text":""},{"location":"reference/rra_tools/#rra_tools.jobmon._process_args","title":"<code>_process_args(args: dict[str, Collection[Any] | Any] | None) -&gt; tuple[dict[str, Collection[Any]], str]</code>","text":"<p>Process arguments for a task.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon._process_args--parameters","title":"Parameters","text":"<p>args     The arguments to process.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon._process_args--returns","title":"Returns","text":"<p>tuple[dict[str, Collection[Any]], str]     The names of all non-flag and non-count arguments and the string     representation of the arguments.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def _process_args(\n    args: dict[str, Collection[Any] | Any] | None,\n) -&gt; tuple[dict[str, Collection[Any]], str]:\n    \"\"\"Process arguments for a task.\n\n    Parameters\n    ----------\n    args\n        The arguments to process.\n\n    Returns\n    -------\n    tuple[dict[str, Collection[Any]], str]\n        The names of all non-flag and non-count arguments and the string\n        representation of the arguments.\n    \"\"\"\n    if args is None:\n        return {}, \"\"\n    out_args = {}\n    arg_parts = []\n    for k, v in args.items():\n        if v is not None:\n            arg_parts.append(f\"--{k} {{{k.replace('-', '_')}}}\")\n            out_args[k.replace(\"-\", \"_\")] = v\n        elif len(k) == 1 or k in [\"v\", \"vv\", \"vvv\"]:\n            arg_parts.append(f\"-{k}\")\n        else:\n            arg_parts.append(f\"--{k}\")\n    arg_string = \" \".join(arg_parts)\n    return out_args, arg_string\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.jobmon.build_parallel_task_graph","title":"<code>build_parallel_task_graph(jobmon_tool, runner: str, task_name: str, task_resources: dict[str, str | int], *, node_args: dict[str, Collection[Any] | None] | None = None, flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None, task_args: dict[str, Any] | None = None, op_args: dict[str, Any] | None = None, max_attempts: int | None = None) -&gt; list[Any]</code>","text":"<p>Build a parallel task graph for jobmon.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon.build_parallel_task_graph--parameters","title":"Parameters","text":"<p>jobmon_tool     The jobmon tool. runner     The runner to use for the task. task_name     The name of the task. node_args     The arguments to the task script that are unique to each task. The keys of     the dict are the names of the arguments and the values are lists of the     values to use for each task. A dict with multiple keys will result in a     cartesian product of the values. Mutually exclusive with     flat_node_args. flat_node_args     The arguments to the task script that are unique to each task. The first     element of the tuple is the names of the arguments and the second element     is a list of tuples of the values to use for each task. This can be used     to avoid the cartesian product of node_args and just run a subset of the     possible tasks. Mutually exclusive with node_args. task_args     The arguments to the task script that are the same for each task, but     alter the behavior of the task (e.g. input and output root directories). op_args     Arguments that are passed to the task script but do not alter the logical     behavior of the task (e.g. number of cores, logging verbosity). task_resources     The resources to allocate to the task. max_attempts     The maximum number of attempts to make for each task.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon.build_parallel_task_graph--returns","title":"Returns","text":"<p>list     A list of tasks to run.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def build_parallel_task_graph(  # type: ignore[no-untyped-def] # noqa: PLR0913\n    jobmon_tool,\n    runner: str,\n    task_name: str,\n    task_resources: dict[str, str | int],\n    *,\n    node_args: dict[str, Collection[Any] | None] | None = None,\n    flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None,\n    task_args: dict[str, Any] | None = None,\n    op_args: dict[str, Any] | None = None,\n    max_attempts: int | None = None,\n) -&gt; list[Any]:\n    \"\"\"Build a parallel task graph for jobmon.\n\n    Parameters\n    ----------\n    jobmon_tool\n        The jobmon tool.\n    runner\n        The runner to use for the task.\n    task_name\n        The name of the task.\n    node_args\n        The arguments to the task script that are unique to each task. The keys of\n        the dict are the names of the arguments and the values are lists of the\n        values to use for each task. A dict with multiple keys will result in a\n        cartesian product of the values. Mutually exclusive with\n        flat_node_args.\n    flat_node_args\n        The arguments to the task script that are unique to each task. The first\n        element of the tuple is the names of the arguments and the second element\n        is a list of tuples of the values to use for each task. This can be used\n        to avoid the cartesian product of node_args and just run a subset of the\n        possible tasks. Mutually exclusive with node_args.\n    task_args\n        The arguments to the task script that are the same for each task, but\n        alter the behavior of the task (e.g. input and output root directories).\n    op_args\n        Arguments that are passed to the task script but do not alter the logical\n        behavior of the task (e.g. number of cores, logging verbosity).\n    task_resources\n        The resources to allocate to the task.\n    max_attempts\n        The maximum number of attempts to make for each task.\n\n    Returns\n    -------\n    list\n        A list of tasks to run.\n    \"\"\"\n    for arg in [\"stdout\", \"stderr\"]:\n        task_resources[arg] = str(task_resources.get(arg, \"/tmp\"))  # noqa: S108\n\n    if node_args is not None and flat_node_args is not None:\n        msg = \"node_args and flat_node_args are mutually exclusive.\"\n        raise ValueError(msg)\n    if flat_node_args is not None:\n        node_arg_string = \" \".join(\n            f\"--{arg} {{{arg.replace('-', '_')}}}\" for arg in flat_node_args[0]\n        )\n        flat_node_args = (\n            tuple([arg.replace(\"-\", \"_\") for arg in flat_node_args[0]]),\n            flat_node_args[1],\n        )\n        clean_node_args: dict[str, Collection[Any]] = {k: [] for k in flat_node_args[0]}\n    else:\n        clean_node_args, node_arg_string = _process_args(node_args)\n    clean_task_args, task_arg_string = _process_args(task_args)\n    clean_op_args, op_arg_string = _process_args(op_args)\n\n    command_template = (\n        f\"{runner} {task_name} {node_arg_string} {task_arg_string} {op_arg_string}\"\n    )\n\n    task_template = jobmon_tool.get_task_template(\n        default_compute_resources=task_resources,\n        template_name=f\"{task_name}_task_template\",\n        default_cluster_name=\"slurm\",\n        command_template=command_template,\n        node_args=list(clean_node_args),\n        task_args=list(clean_task_args),\n        op_args=list(clean_op_args),\n    )\n\n    if flat_node_args is not None:\n        tasks = []\n        arg_names, arg_values = flat_node_args\n        for args in arg_values:\n            task_args = {\n                **dict(zip(arg_names, args, strict=False)),\n                **clean_task_args,\n                **clean_op_args,\n            }\n            task = task_template.create_task(\n                **task_args,\n                max_attempts=max_attempts,\n            )\n            tasks.append(task)\n    else:\n        tasks = task_template.create_tasks(\n            **clean_node_args,\n            **clean_task_args,\n            **clean_op_args,\n            max_attempts=max_attempts,\n        )\n    return tasks\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.jobmon.get_jobmon_tool","title":"<code>get_jobmon_tool(workflow_name: str)</code>","text":"<p>Get a jobmon tool for a given workflow name with a helpful error message.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon.get_jobmon_tool--parameters","title":"Parameters","text":"<p>workflow_name     The name of the workflow.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon.get_jobmon_tool--returns","title":"Returns","text":"<p>Tool     A jobmon tool.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon.get_jobmon_tool--raises","title":"Raises","text":"<p>ModuleNotFoundError     If jobmon is not installed.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def get_jobmon_tool(workflow_name: str):  # type: ignore[no-untyped-def]\n    \"\"\"Get a jobmon tool for a given workflow name with a helpful error message.\n\n    Parameters\n    ----------\n    workflow_name\n        The name of the workflow.\n\n    Returns\n    -------\n    Tool\n        A jobmon tool.\n\n    Raises\n    ------\n    ModuleNotFoundError\n        If jobmon is not installed.\n    \"\"\"\n    try:\n        from jobmon.client.tool import Tool  # type: ignore[import-not-found]\n    except ModuleNotFoundError as e:\n        msg = (\n            \"Jobmon is not installed.\\n\"\n            \"Ensure you have a file in your home \"\n            \"directory at '~/.pip/pip.conf' with contents\\n\\n\"\n            \"[global]\\n\"\n            \"extra-index-url = https://artifactory.ihme.washington.edu/artifactory/api/pypi/pypi-shared/simple\\n\"\n            \"trusted-host = artifactory.ihme.washington.edu/artifactory/api/pypi/pypi-shared\\n\\n\"\n            \"and run 'pip install jobmon_installer_ihme' to install jobmon.\"\n        )\n        raise ModuleNotFoundError(msg) from e\n\n    return Tool(workflow_name)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.jobmon.run_parallel","title":"<code>run_parallel(runner: str, task_name: str, task_resources: dict[str, str | int], *, node_args: dict[str, Collection[Any] | None] | None = None, flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None, task_args: dict[str, Any] | None = None, op_args: dict[str, Any] | None = None, concurrency_limit: int = 10000, max_attempts: int | None = None, log_root: str | Path | None = None, log_method: Callable[[str], None] = print) -&gt; str</code>","text":"<p>Run a parallel set of tasks using Jobmon.</p> <p>This helper function encapsulates one of the simpler workflow patterns in Jobmon: a set of tasks that run in parallel, each with the same command but different arguments. More complicated workflows should be implemented directly.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon.run_parallel--parameters","title":"Parameters","text":"<p>runner     The runner to use for the task. Default is 'rptask'. task_name     The name of the task to run.  Will also be used as the tool and workflow name. task_resources     The resources to allocate to the task. node_args     The arguments to the task script that are unique to each task. The keys of     the dict are the names of the arguments and the values are lists of the     values to use for each task. A dict with multiple keys will result in a     cartesian product of the values. Mutually exclusive with     flat_node_args. flat_node_args     The arguments to the task script that are unique to each task. The first     element of the tuple is the names of the arguments and the second element     is a list of tuples of the values to use for each task. This can be used     to avoid the cartesian product of node_args and just run a subset of the     possible tasks. Mutually exclusive with node_args. task_args     The arguments to the task script that are the same for each task, but     alter the behavior of the task (e.g. input and output root directories). op_args     Arguments that are passed to the task script but do not alter the logical     behavior of the task (e.g. number of cores, logging verbosity). concurrency_limit     The maximum number of tasks to run concurrently. Default is 10000. max_attempts     The maximum number of attempts to make for each task. log_root     The root directory for the logs. Default is None. log_method     The method to use for logging. Default is print.</p>"},{"location":"reference/rra_tools/#rra_tools.jobmon.run_parallel--returns","title":"Returns","text":"<p>str     The status of the workflow.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def run_parallel(  # noqa: PLR0913\n    runner: str,\n    task_name: str,\n    task_resources: dict[str, str | int],\n    *,\n    node_args: dict[str, Collection[Any] | None] | None = None,\n    flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None,\n    task_args: dict[str, Any] | None = None,\n    op_args: dict[str, Any] | None = None,\n    concurrency_limit: int = 10000,\n    max_attempts: int | None = None,\n    log_root: str | Path | None = None,\n    log_method: Callable[[str], None] = print,\n) -&gt; str:\n    \"\"\"Run a parallel set of tasks using Jobmon.\n\n    This helper function encapsulates one of the simpler workflow patterns in Jobmon:\n    a set of tasks that run in parallel, each with the same command but\n    different arguments. More complicated workflows should be implemented\n    directly.\n\n    Parameters\n    ----------\n    runner\n        The runner to use for the task. Default is 'rptask'.\n    task_name\n        The name of the task to run.  Will also be used as the tool and workflow name.\n    task_resources\n        The resources to allocate to the task.\n    node_args\n        The arguments to the task script that are unique to each task. The keys of\n        the dict are the names of the arguments and the values are lists of the\n        values to use for each task. A dict with multiple keys will result in a\n        cartesian product of the values. Mutually exclusive with\n        flat_node_args.\n    flat_node_args\n        The arguments to the task script that are unique to each task. The first\n        element of the tuple is the names of the arguments and the second element\n        is a list of tuples of the values to use for each task. This can be used\n        to avoid the cartesian product of node_args and just run a subset of the\n        possible tasks. Mutually exclusive with node_args.\n    task_args\n        The arguments to the task script that are the same for each task, but\n        alter the behavior of the task (e.g. input and output root directories).\n    op_args\n        Arguments that are passed to the task script but do not alter the logical\n        behavior of the task (e.g. number of cores, logging verbosity).\n    concurrency_limit\n        The maximum number of tasks to run concurrently. Default is 10000.\n    max_attempts\n        The maximum number of attempts to make for each task.\n    log_root\n        The root directory for the logs. Default is None.\n    log_method\n        The method to use for logging. Default is print.\n\n    Returns\n    -------\n    str\n        The status of the workflow.\n    \"\"\"\n    if node_args is not None and flat_node_args is not None:\n        msg = \"node_args and flat_node_args are mutually exclusive.\"\n        raise ValueError(msg)\n\n    if log_root is None:\n        if task_args is None or \"output-dir\" not in task_args:\n            msg = (\n                \"The task_args dictionary must contain an 'output-dir' key if no \"\n                \"log_root is provided.\"\n            )\n            raise KeyError(msg)\n        log_root = Path(task_args[\"output-dir\"])\n    log_dir = make_log_dir(log_root)\n    task_resources[\"stdout\"] = str(log_dir / \"output\")\n    task_resources[\"standard_output\"] = str(log_dir / \"output\")\n    task_resources[\"stderr\"] = str(log_dir / \"error\")\n    task_resources[\"standard_error\"] = str(log_dir / \"error\")\n\n    tool = get_jobmon_tool(workflow_name=task_name)\n    workflow = tool.create_workflow(\n        name=f\"{task_name}_{uuid.uuid4()}\",\n        max_concurrently_running=concurrency_limit,\n    )\n\n    tasks = build_parallel_task_graph(\n        jobmon_tool=tool,\n        task_name=task_name,\n        node_args=node_args,\n        flat_node_args=flat_node_args,\n        task_args=task_args,\n        op_args=op_args,\n        task_resources=task_resources,\n        runner=runner,\n        max_attempts=max_attempts,\n    )\n\n    workflow.add_tasks(tasks)\n    return run_workflow(workflow, log_method)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.logging","title":"<code>logging</code>","text":""},{"location":"reference/rra_tools/#rra_tools.logging.add_logging_sink","title":"<code>add_logging_sink(sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path, verbose: int, *, colorize: bool = False, serialize: bool = False) -&gt; None</code>","text":"<p>Add a new output file handle for logging.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def add_logging_sink(\n    sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path,\n    verbose: int,\n    *,\n    colorize: bool = False,\n    serialize: bool = False,\n) -&gt; None:\n    \"\"\"Add a new output file handle for logging.\"\"\"\n    level, message_format = LOG_FORMATS.get(\n        verbose, LOG_FORMATS[max(LOG_FORMATS.keys())]\n    )\n    logger.add(\n        sink,  # type: ignore[arg-type]\n        colorize=colorize,\n        level=level,\n        format=message_format,\n        serialize=serialize,\n        filter={\n            # Suppress logs up to the level provided.\n            \"urllib3\": \"WARNING\",  # Uselessly (for us) noisy.\n        },\n    )\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.logging.configure_logging_to_files","title":"<code>configure_logging_to_files(log_dir: str | Path) -&gt; None</code>","text":"<p>Sets up logging to a file in an output directory.</p> <p>Logs to files are done with the highest verbosity to allow for debugging if necessary.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_files(log_dir: str | Path) -&gt; None:\n    \"\"\"Sets up logging to a file in an output directory.\n\n    Logs to files are done with the highest verbosity to allow\n    for debugging if necessary.\n\n    \"\"\"\n    mkdir(log_dir, exist_ok=True)\n    add_logging_sink(\n        Path(log_dir) / \"main_log.json\",\n        verbose=3,\n        serialize=True,\n    )\n    add_logging_sink(\n        Path(log_dir) / \"main_log.txt\",\n        verbose=3,\n    )\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.logging.configure_logging_to_terminal","title":"<code>configure_logging_to_terminal(verbose: int) -&gt; None</code>","text":"<p>Setup logging to sys.stdout.</p> <p>This is presumed to be one of the first calls made in an application entry point. Any logging that occurs before this call won't be intercepted or handled with the standard logging configuration.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_terminal(verbose: int) -&gt; None:\n    \"\"\"Setup logging to sys.stdout.\n\n    This is presumed to be one of the first calls made in an\n    application entry point. Any logging that occurs before this\n    call won't be intercepted or handled with the standard\n    logging configuration.\n\n    \"\"\"\n    logger.remove(0)  # Clear default configuration\n    add_logging_sink(sys.stdout, verbose, colorize=True)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.logging.config","title":"<code>config</code>","text":""},{"location":"reference/rra_tools/#rra_tools.logging.config.add_logging_sink","title":"<code>add_logging_sink(sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path, verbose: int, *, colorize: bool = False, serialize: bool = False) -&gt; None</code>","text":"<p>Add a new output file handle for logging.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def add_logging_sink(\n    sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path,\n    verbose: int,\n    *,\n    colorize: bool = False,\n    serialize: bool = False,\n) -&gt; None:\n    \"\"\"Add a new output file handle for logging.\"\"\"\n    level, message_format = LOG_FORMATS.get(\n        verbose, LOG_FORMATS[max(LOG_FORMATS.keys())]\n    )\n    logger.add(\n        sink,  # type: ignore[arg-type]\n        colorize=colorize,\n        level=level,\n        format=message_format,\n        serialize=serialize,\n        filter={\n            # Suppress logs up to the level provided.\n            \"urllib3\": \"WARNING\",  # Uselessly (for us) noisy.\n        },\n    )\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.logging.config.configure_logging_to_files","title":"<code>configure_logging_to_files(log_dir: str | Path) -&gt; None</code>","text":"<p>Sets up logging to a file in an output directory.</p> <p>Logs to files are done with the highest verbosity to allow for debugging if necessary.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_files(log_dir: str | Path) -&gt; None:\n    \"\"\"Sets up logging to a file in an output directory.\n\n    Logs to files are done with the highest verbosity to allow\n    for debugging if necessary.\n\n    \"\"\"\n    mkdir(log_dir, exist_ok=True)\n    add_logging_sink(\n        Path(log_dir) / \"main_log.json\",\n        verbose=3,\n        serialize=True,\n    )\n    add_logging_sink(\n        Path(log_dir) / \"main_log.txt\",\n        verbose=3,\n    )\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.logging.config.configure_logging_to_terminal","title":"<code>configure_logging_to_terminal(verbose: int) -&gt; None</code>","text":"<p>Setup logging to sys.stdout.</p> <p>This is presumed to be one of the first calls made in an application entry point. Any logging that occurs before this call won't be intercepted or handled with the standard logging configuration.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_terminal(verbose: int) -&gt; None:\n    \"\"\"Setup logging to sys.stdout.\n\n    This is presumed to be one of the first calls made in an\n    application entry point. Any logging that occurs before this\n    call won't be intercepted or handled with the standard\n    logging configuration.\n\n    \"\"\"\n    logger.remove(0)  # Clear default configuration\n    add_logging_sink(sys.stdout, verbose, colorize=True)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.parallel","title":"<code>parallel</code>","text":"<p>======== Parallel ========</p> <p>This module simplifies the use of multiprocessing. It provides a single function, :func:<code>run_parallel</code>, that runs a function in parallel over a list of arguments.</p>"},{"location":"reference/rra_tools/#rra_tools.parallel.is_notebook","title":"<code>is_notebook() -&gt; bool</code>","text":"<p>Are we running code in a jupyter notebook?</p> <p>Code from https://stackoverflow.com/a/39662359</p> Source code in <code>src/rra_tools/parallel.py</code> <pre><code>def is_notebook() -&gt; bool:\n    \"\"\"Are we running code in a jupyter notebook?\n\n    Code from https://stackoverflow.com/a/39662359\n    \"\"\"\n    try:\n        # The get_ipython function will be in the global namespace if we're in\n        # an ipython-like environment (including jupyter notebooks).\n        shell = get_ipython().__class__.__name__  # type: ignore[name-defined]\n    except NameError:\n        # Probably standard Python interpreter\n        return False\n    else:\n        # Jupyter notebook or qtconsole\n        return shell == \"ZMQInteractiveShell\"  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.parallel.run_parallel","title":"<code>run_parallel(runner: Callable[[T1], T2], arg_list: Collection[T1], *, num_cores: int = 1, progress_bar: bool = False, notebook_fallback: bool = True) -&gt; list[T2]</code>","text":"<p>Runs a single argument function in parallel over a list of arguments.</p> <p>This function dodges multiprocessing if only a single process is requested to make functions more flexible to debugging. It also supports progress bars if requested.</p>"},{"location":"reference/rra_tools/#rra_tools.parallel.run_parallel--parameters","title":"Parameters","text":"<p>runner     A single argument function to be run in parallel. arg_list     A list of arguments to be run over in parallel. num_cores     Maximum number of processes to be run in parallel. If num_cores == 1,     The jobs will be run serially without invoking multiprocessing. progress_bar     Whether to display a progress bar for the running jobs. notebook_fallback     Whether to fallback to standard multiprocessing in a notebook. We use <code>pathos</code>     for multiprocessing as it uses a more robust serialization library, but <code>pathos</code>     has some leaky state and doesn't properly close down child processes when     interrupted in a jupyter notebook.</p>"},{"location":"reference/rra_tools/#rra_tools.parallel.run_parallel--returns","title":"Returns","text":"<p>List[Any]     A list of the results of the parallel calls of the runner.</p> Source code in <code>src/rra_tools/parallel.py</code> <pre><code>def run_parallel[T1, T2](\n    runner: Callable[[T1], T2],\n    arg_list: Collection[T1],\n    *,\n    num_cores: int = 1,\n    progress_bar: bool = False,\n    notebook_fallback: bool = True,\n) -&gt; list[T2]:\n    \"\"\"Runs a single argument function in parallel over a list of arguments.\n\n    This function dodges multiprocessing if only a single process is requested to\n    make functions more flexible to debugging. It also supports progress bars if\n    requested.\n\n    Parameters\n    ----------\n    runner\n        A single argument function to be run in parallel.\n    arg_list\n        A list of arguments to be run over in parallel.\n    num_cores\n        Maximum number of processes to be run in parallel. If num_cores == 1,\n        The jobs will be run serially without invoking multiprocessing.\n    progress_bar\n        Whether to display a progress bar for the running jobs.\n    notebook_fallback\n        Whether to fallback to standard multiprocessing in a notebook. We use `pathos`\n        for multiprocessing as it uses a more robust serialization library, but `pathos`\n        has some leaky state and doesn't properly close down child processes when\n        interrupted in a jupyter notebook.\n\n    Returns\n    -------\n    List[Any]\n        A list of the results of the parallel calls of the runner.\n\n    \"\"\"\n\n    if num_cores == 1:\n        result = []\n        for arg in tqdm.tqdm(arg_list, disable=not progress_bar):\n            result.append(runner(arg))  # noqa: PERF401\n    else:\n        if is_notebook() and notebook_fallback:\n            processing_pool_class = StdLibPool\n        else:\n            processing_pool_class = PathosPool\n\n        with processing_pool_class(num_cores) as pool:\n            result = list(\n                tqdm.tqdm(\n                    pool.imap(runner, arg_list),\n                    total=len(arg_list),\n                    disable=not progress_bar,\n                )\n            )\n    return result\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.plotting","title":"<code>plotting</code>","text":"<p>Plotting utilities for RRA tools.</p>"},{"location":"reference/rra_tools/#rra_tools.plotting.strip_axes","title":"<code>strip_axes(ax: Axes) -&gt; Axes</code>","text":"<p>Despine axis and remove ticks and labels.</p> Source code in <code>src/rra_tools/plotting.py</code> <pre><code>def strip_axes(ax: Axes) -&gt; Axes:\n    \"\"\"Despine axis and remove ticks and labels.\"\"\"\n    sns.despine(ax=ax, left=True, bottom=True)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    return ax\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.plotting.write_or_show","title":"<code>write_or_show(fig: Figure, plot_file: str | Path | None, **savefig_kwargs: Any) -&gt; None</code>","text":"<p>Write the figure to a file or show it.</p> Source code in <code>src/rra_tools/plotting.py</code> <pre><code>def write_or_show(\n    fig: Figure, plot_file: str | Path | None, **savefig_kwargs: Any\n) -&gt; None:\n    \"\"\"Write the figure to a file or show it.\"\"\"\n    if plot_file:\n        fig.savefig(plot_file, **savefig_kwargs)\n        plt.close(fig)\n    else:\n        plt.show()\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.shell_tools","title":"<code>shell_tools</code>","text":""},{"location":"reference/rra_tools/#rra_tools.shell_tools._touch_clean","title":"<code>_touch_clean(path: str | Path, mode: int = 436) -&gt; None</code>","text":"<p>Creates a file with the specified mode, overwriting the file if it exists.</p> <p>This function is a helper function for the <code>touch</code> function. It is not meant to be used outside of this module.</p>"},{"location":"reference/rra_tools/#rra_tools.shell_tools._touch_clean--parameters","title":"Parameters","text":"<p>path     The path of the file to create. mode     The permission mode to use in file creation.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def _touch_clean(path: str | Path, mode: int = 0o664) -&gt; None:\n    \"\"\"Creates a file with the specified mode, overwriting the file if it exists.\n\n    This function is a helper function for the `touch` function. It is not\n    meant to be used outside of this module.\n\n    Parameters\n    ----------\n    path\n        The path of the file to create.\n    mode\n        The permission mode to use in file creation.\n\n    \"\"\"\n    path = Path(path)\n    old_umask = os.umask(0o777 - mode)\n    try:\n        path.touch()\n    finally:\n        os.umask(old_umask)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.mkdir","title":"<code>mkdir(path: str | Path, mode: int = 509, *, exist_ok: bool = False, parents: bool = False) -&gt; None</code>","text":"<p>Creates a directory and its parents with the specified mode.</p> <p>This method is meant to combat permissions errors generated by the default umask behavior when creating parent directories (i.e. ignore the mode argument and use the default permissions).</p>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.mkdir--parameters","title":"Parameters","text":"<p>path     The path of the directory to create. mode     The permission mode to use in directory creation. exist_ok     If False, raises FileExistsError if the directory already exists. parents     If False, raises FileNotFoundError if the directory's parent doesn't     exist.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def mkdir(\n    path: str | Path,\n    mode: int = 0o775,\n    *,\n    exist_ok: bool = False,\n    parents: bool = False,\n) -&gt; None:\n    \"\"\"Creates a directory and its parents with the specified mode.\n\n    This method is meant to combat permissions errors generated by the default\n    umask behavior when creating parent directories (i.e. ignore the mode\n    argument and use the default permissions).\n\n    Parameters\n    ----------\n    path\n        The path of the directory to create.\n    mode\n        The permission mode to use in directory creation.\n    exist_ok\n        If False, raises FileExistsError if the directory already exists.\n    parents\n        If False, raises FileNotFoundError if the directory's parent doesn't\n        exist.\n\n    \"\"\"\n    path = Path(path)\n    old_umask = os.umask(0o777 - mode)\n    try:\n        path.mkdir(exist_ok=exist_ok, parents=parents)\n    finally:\n        os.umask(old_umask)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.touch","title":"<code>touch(path: str | Path, mode: int = 436, *, exist_ok: bool = False, clobber: bool = False) -&gt; None</code>","text":"<p>Creates a file with the specified mode.</p>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.touch--parameters","title":"Parameters","text":"<p>path     The path of the file to create. mode     The permission mode to use in file creation. exist_ok     If False, raises FileExistsError if the file already exists.     If True, raises FileExistsError if path is a directory or permissions     do not match the mode argument. clobber     If True, overwrites the file if it already exists.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def touch(\n    path: str | Path,\n    mode: int = 0o664,\n    *,\n    exist_ok: bool = False,\n    clobber: bool = False,\n) -&gt; None:\n    \"\"\"Creates a file with the specified mode.\n\n    Parameters\n    ----------\n    path\n        The path of the file to create.\n    mode\n        The permission mode to use in file creation.\n    exist_ok\n        If False, raises FileExistsError if the file already exists.\n        If True, raises FileExistsError if path is a directory or permissions\n        do not match the mode argument.\n    clobber\n        If True, overwrites the file if it already exists.\n\n    \"\"\"\n    path = Path(path)\n    if path.exists():\n        if not path.is_file():\n            msg = f\"File exists at {path} and is not a file.\"\n            raise FileExistsError(msg)\n        if not exist_ok and not clobber:\n            msg = f\"File exists at {path}.\"\n            raise FileExistsError(msg)\n\n        if clobber:\n            path.unlink()\n            _touch_clean(path, mode)\n        else:\n            path_chmod = path.stat().st_mode &amp; 0o777\n            if path_chmod != mode:\n                msg = (\n                    f\"File exists at {path} with mode {oct(path_chmod)} \"\n                    f\"and not {oct(mode)}.\"\n                )\n                raise FileExistsError(msg)\n    else:\n        _touch_clean(path, mode)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.unzip_and_delete_archive","title":"<code>unzip_and_delete_archive(archive_path: str | Path, output_path: str | Path) -&gt; None</code>","text":"<p>Unzips an archive file to a directory and then deletes the archive.</p>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.unzip_and_delete_archive--parameters","title":"Parameters","text":"<p>archive_path     The path to the archive we want to unzip. output_path     The place to store the unzipped contents.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def unzip_and_delete_archive(archive_path: str | Path, output_path: str | Path) -&gt; None:\n    \"\"\"Unzips an archive file to a directory and then deletes the archive.\n\n    Parameters\n    ----------\n    archive_path\n        The path to the archive we want to unzip.\n    output_path\n        The place to store the unzipped contents.\n\n    \"\"\"\n    subprocess.run(shlex.split(f\"unzip {archive_path} -d {output_path}\"), check=True)\n    subprocess.run(shlex.split(f\"rm {archive_path}\"), check=True)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.wget","title":"<code>wget(url: str, output_path: str | Path) -&gt; None</code>","text":"<p>Retrieves content at the url and stores it at an output path.</p>"},{"location":"reference/rra_tools/#rra_tools.shell_tools.wget--parameters","title":"Parameters","text":"<p>url     The url to retrieve the content from. output_path     Where we'll save the output to.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def wget(url: str, output_path: str | Path) -&gt; None:\n    \"\"\"Retrieves content at the url and stores it at an output path.\n\n    Parameters\n    ----------\n    url\n        The url to retrieve the content from.\n    output_path\n        Where we'll save the output to.\n\n    \"\"\"\n    subprocess.run(shlex.split(f\"wget -O {output_path} {url}\"), check=True)\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.translate","title":"<code>translate</code>","text":""},{"location":"reference/rra_tools/#rra_tools.translate.translate_dataframe","title":"<code>translate_dataframe(df: pd.DataFrame, columns: list[str] | None = None, source_language: str = 'auto', target_language: str = 'en') -&gt; pd.DataFrame</code>","text":"<p>Translate a dataframe using Google Translate.</p>"},{"location":"reference/rra_tools/#rra_tools.translate.translate_dataframe--parameters","title":"Parameters","text":"<p>df     The dataframe to translate. columns     The columns to translate. If None, all columns will be translated. source_language     The language of the input text. If 'auto', Google Translate will attempt     to detect the language. target_language     The language to translate to.</p>"},{"location":"reference/rra_tools/#rra_tools.translate.translate_dataframe--returns","title":"Returns","text":"<p>pd.DataFrame     The translated dataframe.</p> Source code in <code>src/rra_tools/translate.py</code> <pre><code>def translate_dataframe(\n    df: pd.DataFrame,\n    columns: list[str] | None = None,\n    source_language: str = \"auto\",\n    target_language: str = \"en\",\n) -&gt; pd.DataFrame:\n    \"\"\"Translate a dataframe using Google Translate.\n\n    Parameters\n    ----------\n    df\n        The dataframe to translate.\n    columns\n        The columns to translate. If None, all columns will be translated.\n    source_language\n        The language of the input text. If 'auto', Google Translate will attempt\n        to detect the language.\n    target_language\n        The language to translate to.\n\n    Returns\n    -------\n    pd.DataFrame\n        The translated dataframe.\n    \"\"\"\n    df = df.copy()  # don't mutate the original dataframe\n\n    if columns is None:\n        columns = df.columns.tolist()\n    translator = GoogleTranslator(source=source_language, target=target_language)\n    for col in columns:\n        df[f\"{col}\"] = translator.translate_batch(df[col].tolist())\n    return df\n</code></pre>"},{"location":"reference/rra_tools/#rra_tools.translate.translate_text_file","title":"<code>translate_text_file(input_path: str | Path, output_path: str | Path, source_language: str = 'auto', target_language: str = 'en', input_encoding: str = 'utf-8') -&gt; None</code>","text":"<p>Translate a text file line-by-line using Google Translate.</p> <p>This function will produce a new file interleaving the original lines with the translated lines. Google Translate is sometimes a little silly and so having the original line next to the translated line can be helpful, especially if you have some knowledge of the source language.</p>"},{"location":"reference/rra_tools/#rra_tools.translate.translate_text_file--parameters","title":"Parameters","text":"<p>input_path     The path to the input file. output_path     The path to the output file. source_language     The language of the input text. If 'auto', Google Translate will attempt     to detect the language. target_language     The language to translate to. input_encoding     The encoding of the input file.</p> Source code in <code>src/rra_tools/translate.py</code> <pre><code>def translate_text_file(\n    input_path: str | Path,\n    output_path: str | Path,\n    source_language: str = \"auto\",\n    target_language: str = \"en\",\n    input_encoding: str = \"utf-8\",\n) -&gt; None:\n    \"\"\"Translate a text file line-by-line using Google Translate.\n\n    This function will produce a new file interleaving the original lines with\n    the translated lines. Google Translate is sometimes a little silly and so\n    having the original line next to the translated line can be helpful, especially\n    if you have some knowledge of the source language.\n\n    Parameters\n    ----------\n    input_path\n        The path to the input file.\n    output_path\n        The path to the output file.\n    source_language\n        The language of the input text. If 'auto', Google Translate will attempt\n        to detect the language.\n    target_language\n        The language to translate to.\n    input_encoding\n        The encoding of the input file.\n    \"\"\"\n    with Path(input_path, encoding=input_encoding).open() as f:\n        lines = f.readlines()\n\n    translator = GoogleTranslator(source=source_language, target=target_language)\n    translated_lines = translator.translate_batch(lines)\n\n    with Path(output_path).open(\"w\") as f:\n        for in_line, out_line in zip(lines, translated_lines, strict=False):\n            if in_line:\n                f.write(f\"{in_line.strip()}\\n{out_line.strip()}\\n\\n\")\n</code></pre>"},{"location":"reference/rra_tools/jobmon/","title":"jobmon","text":""},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon._process_args","title":"<code>_process_args(args: dict[str, Collection[Any] | Any] | None) -&gt; tuple[dict[str, Collection[Any]], str]</code>","text":"<p>Process arguments for a task.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon._process_args--parameters","title":"Parameters","text":"<p>args     The arguments to process.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon._process_args--returns","title":"Returns","text":"<p>tuple[dict[str, Collection[Any]], str]     The names of all non-flag and non-count arguments and the string     representation of the arguments.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def _process_args(\n    args: dict[str, Collection[Any] | Any] | None,\n) -&gt; tuple[dict[str, Collection[Any]], str]:\n    \"\"\"Process arguments for a task.\n\n    Parameters\n    ----------\n    args\n        The arguments to process.\n\n    Returns\n    -------\n    tuple[dict[str, Collection[Any]], str]\n        The names of all non-flag and non-count arguments and the string\n        representation of the arguments.\n    \"\"\"\n    if args is None:\n        return {}, \"\"\n    out_args = {}\n    arg_parts = []\n    for k, v in args.items():\n        if v is not None:\n            arg_parts.append(f\"--{k} {{{k.replace('-', '_')}}}\")\n            out_args[k.replace(\"-\", \"_\")] = v\n        elif len(k) == 1 or k in [\"v\", \"vv\", \"vvv\"]:\n            arg_parts.append(f\"-{k}\")\n        else:\n            arg_parts.append(f\"--{k}\")\n    arg_string = \" \".join(arg_parts)\n    return out_args, arg_string\n</code></pre>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.build_parallel_task_graph","title":"<code>build_parallel_task_graph(jobmon_tool, runner: str, task_name: str, task_resources: dict[str, str | int], *, node_args: dict[str, Collection[Any] | None] | None = None, flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None, task_args: dict[str, Any] | None = None, op_args: dict[str, Any] | None = None, max_attempts: int | None = None) -&gt; list[Any]</code>","text":"<p>Build a parallel task graph for jobmon.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.build_parallel_task_graph--parameters","title":"Parameters","text":"<p>jobmon_tool     The jobmon tool. runner     The runner to use for the task. task_name     The name of the task. node_args     The arguments to the task script that are unique to each task. The keys of     the dict are the names of the arguments and the values are lists of the     values to use for each task. A dict with multiple keys will result in a     cartesian product of the values. Mutually exclusive with     flat_node_args. flat_node_args     The arguments to the task script that are unique to each task. The first     element of the tuple is the names of the arguments and the second element     is a list of tuples of the values to use for each task. This can be used     to avoid the cartesian product of node_args and just run a subset of the     possible tasks. Mutually exclusive with node_args. task_args     The arguments to the task script that are the same for each task, but     alter the behavior of the task (e.g. input and output root directories). op_args     Arguments that are passed to the task script but do not alter the logical     behavior of the task (e.g. number of cores, logging verbosity). task_resources     The resources to allocate to the task. max_attempts     The maximum number of attempts to make for each task.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.build_parallel_task_graph--returns","title":"Returns","text":"<p>list     A list of tasks to run.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def build_parallel_task_graph(  # type: ignore[no-untyped-def] # noqa: PLR0913\n    jobmon_tool,\n    runner: str,\n    task_name: str,\n    task_resources: dict[str, str | int],\n    *,\n    node_args: dict[str, Collection[Any] | None] | None = None,\n    flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None,\n    task_args: dict[str, Any] | None = None,\n    op_args: dict[str, Any] | None = None,\n    max_attempts: int | None = None,\n) -&gt; list[Any]:\n    \"\"\"Build a parallel task graph for jobmon.\n\n    Parameters\n    ----------\n    jobmon_tool\n        The jobmon tool.\n    runner\n        The runner to use for the task.\n    task_name\n        The name of the task.\n    node_args\n        The arguments to the task script that are unique to each task. The keys of\n        the dict are the names of the arguments and the values are lists of the\n        values to use for each task. A dict with multiple keys will result in a\n        cartesian product of the values. Mutually exclusive with\n        flat_node_args.\n    flat_node_args\n        The arguments to the task script that are unique to each task. The first\n        element of the tuple is the names of the arguments and the second element\n        is a list of tuples of the values to use for each task. This can be used\n        to avoid the cartesian product of node_args and just run a subset of the\n        possible tasks. Mutually exclusive with node_args.\n    task_args\n        The arguments to the task script that are the same for each task, but\n        alter the behavior of the task (e.g. input and output root directories).\n    op_args\n        Arguments that are passed to the task script but do not alter the logical\n        behavior of the task (e.g. number of cores, logging verbosity).\n    task_resources\n        The resources to allocate to the task.\n    max_attempts\n        The maximum number of attempts to make for each task.\n\n    Returns\n    -------\n    list\n        A list of tasks to run.\n    \"\"\"\n    for arg in [\"stdout\", \"stderr\"]:\n        task_resources[arg] = str(task_resources.get(arg, \"/tmp\"))  # noqa: S108\n\n    if node_args is not None and flat_node_args is not None:\n        msg = \"node_args and flat_node_args are mutually exclusive.\"\n        raise ValueError(msg)\n    if flat_node_args is not None:\n        node_arg_string = \" \".join(\n            f\"--{arg} {{{arg.replace('-', '_')}}}\" for arg in flat_node_args[0]\n        )\n        flat_node_args = (\n            tuple([arg.replace(\"-\", \"_\") for arg in flat_node_args[0]]),\n            flat_node_args[1],\n        )\n        clean_node_args: dict[str, Collection[Any]] = {k: [] for k in flat_node_args[0]}\n    else:\n        clean_node_args, node_arg_string = _process_args(node_args)\n    clean_task_args, task_arg_string = _process_args(task_args)\n    clean_op_args, op_arg_string = _process_args(op_args)\n\n    command_template = (\n        f\"{runner} {task_name} {node_arg_string} {task_arg_string} {op_arg_string}\"\n    )\n\n    task_template = jobmon_tool.get_task_template(\n        default_compute_resources=task_resources,\n        template_name=f\"{task_name}_task_template\",\n        default_cluster_name=\"slurm\",\n        command_template=command_template,\n        node_args=list(clean_node_args),\n        task_args=list(clean_task_args),\n        op_args=list(clean_op_args),\n    )\n\n    if flat_node_args is not None:\n        tasks = []\n        arg_names, arg_values = flat_node_args\n        for args in arg_values:\n            task_args = {\n                **dict(zip(arg_names, args, strict=False)),\n                **clean_task_args,\n                **clean_op_args,\n            }\n            task = task_template.create_task(\n                **task_args,\n                max_attempts=max_attempts,\n            )\n            tasks.append(task)\n    else:\n        tasks = task_template.create_tasks(\n            **clean_node_args,\n            **clean_task_args,\n            **clean_op_args,\n            max_attempts=max_attempts,\n        )\n    return tasks\n</code></pre>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.get_jobmon_tool","title":"<code>get_jobmon_tool(workflow_name: str)</code>","text":"<p>Get a jobmon tool for a given workflow name with a helpful error message.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.get_jobmon_tool--parameters","title":"Parameters","text":"<p>workflow_name     The name of the workflow.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.get_jobmon_tool--returns","title":"Returns","text":"<p>Tool     A jobmon tool.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.get_jobmon_tool--raises","title":"Raises","text":"<p>ModuleNotFoundError     If jobmon is not installed.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def get_jobmon_tool(workflow_name: str):  # type: ignore[no-untyped-def]\n    \"\"\"Get a jobmon tool for a given workflow name with a helpful error message.\n\n    Parameters\n    ----------\n    workflow_name\n        The name of the workflow.\n\n    Returns\n    -------\n    Tool\n        A jobmon tool.\n\n    Raises\n    ------\n    ModuleNotFoundError\n        If jobmon is not installed.\n    \"\"\"\n    try:\n        from jobmon.client.tool import Tool  # type: ignore[import-not-found]\n    except ModuleNotFoundError as e:\n        msg = (\n            \"Jobmon is not installed.\\n\"\n            \"Ensure you have a file in your home \"\n            \"directory at '~/.pip/pip.conf' with contents\\n\\n\"\n            \"[global]\\n\"\n            \"extra-index-url = https://artifactory.ihme.washington.edu/artifactory/api/pypi/pypi-shared/simple\\n\"\n            \"trusted-host = artifactory.ihme.washington.edu/artifactory/api/pypi/pypi-shared\\n\\n\"\n            \"and run 'pip install jobmon_installer_ihme' to install jobmon.\"\n        )\n        raise ModuleNotFoundError(msg) from e\n\n    return Tool(workflow_name)\n</code></pre>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.run_parallel","title":"<code>run_parallel(runner: str, task_name: str, task_resources: dict[str, str | int], *, node_args: dict[str, Collection[Any] | None] | None = None, flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None, task_args: dict[str, Any] | None = None, op_args: dict[str, Any] | None = None, concurrency_limit: int = 10000, max_attempts: int | None = None, log_root: str | Path | None = None, log_method: Callable[[str], None] = print) -&gt; str</code>","text":"<p>Run a parallel set of tasks using Jobmon.</p> <p>This helper function encapsulates one of the simpler workflow patterns in Jobmon: a set of tasks that run in parallel, each with the same command but different arguments. More complicated workflows should be implemented directly.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.run_parallel--parameters","title":"Parameters","text":"<p>runner     The runner to use for the task. Default is 'rptask'. task_name     The name of the task to run.  Will also be used as the tool and workflow name. task_resources     The resources to allocate to the task. node_args     The arguments to the task script that are unique to each task. The keys of     the dict are the names of the arguments and the values are lists of the     values to use for each task. A dict with multiple keys will result in a     cartesian product of the values. Mutually exclusive with     flat_node_args. flat_node_args     The arguments to the task script that are unique to each task. The first     element of the tuple is the names of the arguments and the second element     is a list of tuples of the values to use for each task. This can be used     to avoid the cartesian product of node_args and just run a subset of the     possible tasks. Mutually exclusive with node_args. task_args     The arguments to the task script that are the same for each task, but     alter the behavior of the task (e.g. input and output root directories). op_args     Arguments that are passed to the task script but do not alter the logical     behavior of the task (e.g. number of cores, logging verbosity). concurrency_limit     The maximum number of tasks to run concurrently. Default is 10000. max_attempts     The maximum number of attempts to make for each task. log_root     The root directory for the logs. Default is None. log_method     The method to use for logging. Default is print.</p>"},{"location":"reference/rra_tools/jobmon/#rra_tools.jobmon.run_parallel--returns","title":"Returns","text":"<p>str     The status of the workflow.</p> Source code in <code>src/rra_tools/jobmon.py</code> <pre><code>def run_parallel(  # noqa: PLR0913\n    runner: str,\n    task_name: str,\n    task_resources: dict[str, str | int],\n    *,\n    node_args: dict[str, Collection[Any] | None] | None = None,\n    flat_node_args: tuple[tuple[str, ...], Collection[tuple[Any, ...]]] | None = None,\n    task_args: dict[str, Any] | None = None,\n    op_args: dict[str, Any] | None = None,\n    concurrency_limit: int = 10000,\n    max_attempts: int | None = None,\n    log_root: str | Path | None = None,\n    log_method: Callable[[str], None] = print,\n) -&gt; str:\n    \"\"\"Run a parallel set of tasks using Jobmon.\n\n    This helper function encapsulates one of the simpler workflow patterns in Jobmon:\n    a set of tasks that run in parallel, each with the same command but\n    different arguments. More complicated workflows should be implemented\n    directly.\n\n    Parameters\n    ----------\n    runner\n        The runner to use for the task. Default is 'rptask'.\n    task_name\n        The name of the task to run.  Will also be used as the tool and workflow name.\n    task_resources\n        The resources to allocate to the task.\n    node_args\n        The arguments to the task script that are unique to each task. The keys of\n        the dict are the names of the arguments and the values are lists of the\n        values to use for each task. A dict with multiple keys will result in a\n        cartesian product of the values. Mutually exclusive with\n        flat_node_args.\n    flat_node_args\n        The arguments to the task script that are unique to each task. The first\n        element of the tuple is the names of the arguments and the second element\n        is a list of tuples of the values to use for each task. This can be used\n        to avoid the cartesian product of node_args and just run a subset of the\n        possible tasks. Mutually exclusive with node_args.\n    task_args\n        The arguments to the task script that are the same for each task, but\n        alter the behavior of the task (e.g. input and output root directories).\n    op_args\n        Arguments that are passed to the task script but do not alter the logical\n        behavior of the task (e.g. number of cores, logging verbosity).\n    concurrency_limit\n        The maximum number of tasks to run concurrently. Default is 10000.\n    max_attempts\n        The maximum number of attempts to make for each task.\n    log_root\n        The root directory for the logs. Default is None.\n    log_method\n        The method to use for logging. Default is print.\n\n    Returns\n    -------\n    str\n        The status of the workflow.\n    \"\"\"\n    if node_args is not None and flat_node_args is not None:\n        msg = \"node_args and flat_node_args are mutually exclusive.\"\n        raise ValueError(msg)\n\n    if log_root is None:\n        if task_args is None or \"output-dir\" not in task_args:\n            msg = (\n                \"The task_args dictionary must contain an 'output-dir' key if no \"\n                \"log_root is provided.\"\n            )\n            raise KeyError(msg)\n        log_root = Path(task_args[\"output-dir\"])\n    log_dir = make_log_dir(log_root)\n    task_resources[\"stdout\"] = str(log_dir / \"output\")\n    task_resources[\"standard_output\"] = str(log_dir / \"output\")\n    task_resources[\"stderr\"] = str(log_dir / \"error\")\n    task_resources[\"standard_error\"] = str(log_dir / \"error\")\n\n    tool = get_jobmon_tool(workflow_name=task_name)\n    workflow = tool.create_workflow(\n        name=f\"{task_name}_{uuid.uuid4()}\",\n        max_concurrently_running=concurrency_limit,\n    )\n\n    tasks = build_parallel_task_graph(\n        jobmon_tool=tool,\n        task_name=task_name,\n        node_args=node_args,\n        flat_node_args=flat_node_args,\n        task_args=task_args,\n        op_args=op_args,\n        task_resources=task_resources,\n        runner=runner,\n        max_attempts=max_attempts,\n    )\n\n    workflow.add_tasks(tasks)\n    return run_workflow(workflow, log_method)\n</code></pre>"},{"location":"reference/rra_tools/parallel/","title":"parallel","text":"<p>======== Parallel ========</p> <p>This module simplifies the use of multiprocessing. It provides a single function, :func:<code>run_parallel</code>, that runs a function in parallel over a list of arguments.</p>"},{"location":"reference/rra_tools/parallel/#rra_tools.parallel.is_notebook","title":"<code>is_notebook() -&gt; bool</code>","text":"<p>Are we running code in a jupyter notebook?</p> <p>Code from https://stackoverflow.com/a/39662359</p> Source code in <code>src/rra_tools/parallel.py</code> <pre><code>def is_notebook() -&gt; bool:\n    \"\"\"Are we running code in a jupyter notebook?\n\n    Code from https://stackoverflow.com/a/39662359\n    \"\"\"\n    try:\n        # The get_ipython function will be in the global namespace if we're in\n        # an ipython-like environment (including jupyter notebooks).\n        shell = get_ipython().__class__.__name__  # type: ignore[name-defined]\n    except NameError:\n        # Probably standard Python interpreter\n        return False\n    else:\n        # Jupyter notebook or qtconsole\n        return shell == \"ZMQInteractiveShell\"  # type: ignore[no-any-return]\n</code></pre>"},{"location":"reference/rra_tools/parallel/#rra_tools.parallel.run_parallel","title":"<code>run_parallel(runner: Callable[[T1], T2], arg_list: Collection[T1], *, num_cores: int = 1, progress_bar: bool = False, notebook_fallback: bool = True) -&gt; list[T2]</code>","text":"<p>Runs a single argument function in parallel over a list of arguments.</p> <p>This function dodges multiprocessing if only a single process is requested to make functions more flexible to debugging. It also supports progress bars if requested.</p>"},{"location":"reference/rra_tools/parallel/#rra_tools.parallel.run_parallel--parameters","title":"Parameters","text":"<p>runner     A single argument function to be run in parallel. arg_list     A list of arguments to be run over in parallel. num_cores     Maximum number of processes to be run in parallel. If num_cores == 1,     The jobs will be run serially without invoking multiprocessing. progress_bar     Whether to display a progress bar for the running jobs. notebook_fallback     Whether to fallback to standard multiprocessing in a notebook. We use <code>pathos</code>     for multiprocessing as it uses a more robust serialization library, but <code>pathos</code>     has some leaky state and doesn't properly close down child processes when     interrupted in a jupyter notebook.</p>"},{"location":"reference/rra_tools/parallel/#rra_tools.parallel.run_parallel--returns","title":"Returns","text":"<p>List[Any]     A list of the results of the parallel calls of the runner.</p> Source code in <code>src/rra_tools/parallel.py</code> <pre><code>def run_parallel[T1, T2](\n    runner: Callable[[T1], T2],\n    arg_list: Collection[T1],\n    *,\n    num_cores: int = 1,\n    progress_bar: bool = False,\n    notebook_fallback: bool = True,\n) -&gt; list[T2]:\n    \"\"\"Runs a single argument function in parallel over a list of arguments.\n\n    This function dodges multiprocessing if only a single process is requested to\n    make functions more flexible to debugging. It also supports progress bars if\n    requested.\n\n    Parameters\n    ----------\n    runner\n        A single argument function to be run in parallel.\n    arg_list\n        A list of arguments to be run over in parallel.\n    num_cores\n        Maximum number of processes to be run in parallel. If num_cores == 1,\n        The jobs will be run serially without invoking multiprocessing.\n    progress_bar\n        Whether to display a progress bar for the running jobs.\n    notebook_fallback\n        Whether to fallback to standard multiprocessing in a notebook. We use `pathos`\n        for multiprocessing as it uses a more robust serialization library, but `pathos`\n        has some leaky state and doesn't properly close down child processes when\n        interrupted in a jupyter notebook.\n\n    Returns\n    -------\n    List[Any]\n        A list of the results of the parallel calls of the runner.\n\n    \"\"\"\n\n    if num_cores == 1:\n        result = []\n        for arg in tqdm.tqdm(arg_list, disable=not progress_bar):\n            result.append(runner(arg))  # noqa: PERF401\n    else:\n        if is_notebook() and notebook_fallback:\n            processing_pool_class = StdLibPool\n        else:\n            processing_pool_class = PathosPool\n\n        with processing_pool_class(num_cores) as pool:\n            result = list(\n                tqdm.tqdm(\n                    pool.imap(runner, arg_list),\n                    total=len(arg_list),\n                    disable=not progress_bar,\n                )\n            )\n    return result\n</code></pre>"},{"location":"reference/rra_tools/plotting/","title":"plotting","text":"<p>Plotting utilities for RRA tools.</p>"},{"location":"reference/rra_tools/plotting/#rra_tools.plotting.strip_axes","title":"<code>strip_axes(ax: Axes) -&gt; Axes</code>","text":"<p>Despine axis and remove ticks and labels.</p> Source code in <code>src/rra_tools/plotting.py</code> <pre><code>def strip_axes(ax: Axes) -&gt; Axes:\n    \"\"\"Despine axis and remove ticks and labels.\"\"\"\n    sns.despine(ax=ax, left=True, bottom=True)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    return ax\n</code></pre>"},{"location":"reference/rra_tools/plotting/#rra_tools.plotting.write_or_show","title":"<code>write_or_show(fig: Figure, plot_file: str | Path | None, **savefig_kwargs: Any) -&gt; None</code>","text":"<p>Write the figure to a file or show it.</p> Source code in <code>src/rra_tools/plotting.py</code> <pre><code>def write_or_show(\n    fig: Figure, plot_file: str | Path | None, **savefig_kwargs: Any\n) -&gt; None:\n    \"\"\"Write the figure to a file or show it.\"\"\"\n    if plot_file:\n        fig.savefig(plot_file, **savefig_kwargs)\n        plt.close(fig)\n    else:\n        plt.show()\n</code></pre>"},{"location":"reference/rra_tools/shell_tools/","title":"shell_tools","text":""},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools._touch_clean","title":"<code>_touch_clean(path: str | Path, mode: int = 436) -&gt; None</code>","text":"<p>Creates a file with the specified mode, overwriting the file if it exists.</p> <p>This function is a helper function for the <code>touch</code> function. It is not meant to be used outside of this module.</p>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools._touch_clean--parameters","title":"Parameters","text":"<p>path     The path of the file to create. mode     The permission mode to use in file creation.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def _touch_clean(path: str | Path, mode: int = 0o664) -&gt; None:\n    \"\"\"Creates a file with the specified mode, overwriting the file if it exists.\n\n    This function is a helper function for the `touch` function. It is not\n    meant to be used outside of this module.\n\n    Parameters\n    ----------\n    path\n        The path of the file to create.\n    mode\n        The permission mode to use in file creation.\n\n    \"\"\"\n    path = Path(path)\n    old_umask = os.umask(0o777 - mode)\n    try:\n        path.touch()\n    finally:\n        os.umask(old_umask)\n</code></pre>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.mkdir","title":"<code>mkdir(path: str | Path, mode: int = 509, *, exist_ok: bool = False, parents: bool = False) -&gt; None</code>","text":"<p>Creates a directory and its parents with the specified mode.</p> <p>This method is meant to combat permissions errors generated by the default umask behavior when creating parent directories (i.e. ignore the mode argument and use the default permissions).</p>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.mkdir--parameters","title":"Parameters","text":"<p>path     The path of the directory to create. mode     The permission mode to use in directory creation. exist_ok     If False, raises FileExistsError if the directory already exists. parents     If False, raises FileNotFoundError if the directory's parent doesn't     exist.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def mkdir(\n    path: str | Path,\n    mode: int = 0o775,\n    *,\n    exist_ok: bool = False,\n    parents: bool = False,\n) -&gt; None:\n    \"\"\"Creates a directory and its parents with the specified mode.\n\n    This method is meant to combat permissions errors generated by the default\n    umask behavior when creating parent directories (i.e. ignore the mode\n    argument and use the default permissions).\n\n    Parameters\n    ----------\n    path\n        The path of the directory to create.\n    mode\n        The permission mode to use in directory creation.\n    exist_ok\n        If False, raises FileExistsError if the directory already exists.\n    parents\n        If False, raises FileNotFoundError if the directory's parent doesn't\n        exist.\n\n    \"\"\"\n    path = Path(path)\n    old_umask = os.umask(0o777 - mode)\n    try:\n        path.mkdir(exist_ok=exist_ok, parents=parents)\n    finally:\n        os.umask(old_umask)\n</code></pre>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.touch","title":"<code>touch(path: str | Path, mode: int = 436, *, exist_ok: bool = False, clobber: bool = False) -&gt; None</code>","text":"<p>Creates a file with the specified mode.</p>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.touch--parameters","title":"Parameters","text":"<p>path     The path of the file to create. mode     The permission mode to use in file creation. exist_ok     If False, raises FileExistsError if the file already exists.     If True, raises FileExistsError if path is a directory or permissions     do not match the mode argument. clobber     If True, overwrites the file if it already exists.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def touch(\n    path: str | Path,\n    mode: int = 0o664,\n    *,\n    exist_ok: bool = False,\n    clobber: bool = False,\n) -&gt; None:\n    \"\"\"Creates a file with the specified mode.\n\n    Parameters\n    ----------\n    path\n        The path of the file to create.\n    mode\n        The permission mode to use in file creation.\n    exist_ok\n        If False, raises FileExistsError if the file already exists.\n        If True, raises FileExistsError if path is a directory or permissions\n        do not match the mode argument.\n    clobber\n        If True, overwrites the file if it already exists.\n\n    \"\"\"\n    path = Path(path)\n    if path.exists():\n        if not path.is_file():\n            msg = f\"File exists at {path} and is not a file.\"\n            raise FileExistsError(msg)\n        if not exist_ok and not clobber:\n            msg = f\"File exists at {path}.\"\n            raise FileExistsError(msg)\n\n        if clobber:\n            path.unlink()\n            _touch_clean(path, mode)\n        else:\n            path_chmod = path.stat().st_mode &amp; 0o777\n            if path_chmod != mode:\n                msg = (\n                    f\"File exists at {path} with mode {oct(path_chmod)} \"\n                    f\"and not {oct(mode)}.\"\n                )\n                raise FileExistsError(msg)\n    else:\n        _touch_clean(path, mode)\n</code></pre>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.unzip_and_delete_archive","title":"<code>unzip_and_delete_archive(archive_path: str | Path, output_path: str | Path) -&gt; None</code>","text":"<p>Unzips an archive file to a directory and then deletes the archive.</p>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.unzip_and_delete_archive--parameters","title":"Parameters","text":"<p>archive_path     The path to the archive we want to unzip. output_path     The place to store the unzipped contents.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def unzip_and_delete_archive(archive_path: str | Path, output_path: str | Path) -&gt; None:\n    \"\"\"Unzips an archive file to a directory and then deletes the archive.\n\n    Parameters\n    ----------\n    archive_path\n        The path to the archive we want to unzip.\n    output_path\n        The place to store the unzipped contents.\n\n    \"\"\"\n    subprocess.run(shlex.split(f\"unzip {archive_path} -d {output_path}\"), check=True)\n    subprocess.run(shlex.split(f\"rm {archive_path}\"), check=True)\n</code></pre>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.wget","title":"<code>wget(url: str, output_path: str | Path) -&gt; None</code>","text":"<p>Retrieves content at the url and stores it at an output path.</p>"},{"location":"reference/rra_tools/shell_tools/#rra_tools.shell_tools.wget--parameters","title":"Parameters","text":"<p>url     The url to retrieve the content from. output_path     Where we'll save the output to.</p> Source code in <code>src/rra_tools/shell_tools.py</code> <pre><code>def wget(url: str, output_path: str | Path) -&gt; None:\n    \"\"\"Retrieves content at the url and stores it at an output path.\n\n    Parameters\n    ----------\n    url\n        The url to retrieve the content from.\n    output_path\n        Where we'll save the output to.\n\n    \"\"\"\n    subprocess.run(shlex.split(f\"wget -O {output_path} {url}\"), check=True)\n</code></pre>"},{"location":"reference/rra_tools/translate/","title":"translate","text":""},{"location":"reference/rra_tools/translate/#rra_tools.translate.translate_dataframe","title":"<code>translate_dataframe(df: pd.DataFrame, columns: list[str] | None = None, source_language: str = 'auto', target_language: str = 'en') -&gt; pd.DataFrame</code>","text":"<p>Translate a dataframe using Google Translate.</p>"},{"location":"reference/rra_tools/translate/#rra_tools.translate.translate_dataframe--parameters","title":"Parameters","text":"<p>df     The dataframe to translate. columns     The columns to translate. If None, all columns will be translated. source_language     The language of the input text. If 'auto', Google Translate will attempt     to detect the language. target_language     The language to translate to.</p>"},{"location":"reference/rra_tools/translate/#rra_tools.translate.translate_dataframe--returns","title":"Returns","text":"<p>pd.DataFrame     The translated dataframe.</p> Source code in <code>src/rra_tools/translate.py</code> <pre><code>def translate_dataframe(\n    df: pd.DataFrame,\n    columns: list[str] | None = None,\n    source_language: str = \"auto\",\n    target_language: str = \"en\",\n) -&gt; pd.DataFrame:\n    \"\"\"Translate a dataframe using Google Translate.\n\n    Parameters\n    ----------\n    df\n        The dataframe to translate.\n    columns\n        The columns to translate. If None, all columns will be translated.\n    source_language\n        The language of the input text. If 'auto', Google Translate will attempt\n        to detect the language.\n    target_language\n        The language to translate to.\n\n    Returns\n    -------\n    pd.DataFrame\n        The translated dataframe.\n    \"\"\"\n    df = df.copy()  # don't mutate the original dataframe\n\n    if columns is None:\n        columns = df.columns.tolist()\n    translator = GoogleTranslator(source=source_language, target=target_language)\n    for col in columns:\n        df[f\"{col}\"] = translator.translate_batch(df[col].tolist())\n    return df\n</code></pre>"},{"location":"reference/rra_tools/translate/#rra_tools.translate.translate_text_file","title":"<code>translate_text_file(input_path: str | Path, output_path: str | Path, source_language: str = 'auto', target_language: str = 'en', input_encoding: str = 'utf-8') -&gt; None</code>","text":"<p>Translate a text file line-by-line using Google Translate.</p> <p>This function will produce a new file interleaving the original lines with the translated lines. Google Translate is sometimes a little silly and so having the original line next to the translated line can be helpful, especially if you have some knowledge of the source language.</p>"},{"location":"reference/rra_tools/translate/#rra_tools.translate.translate_text_file--parameters","title":"Parameters","text":"<p>input_path     The path to the input file. output_path     The path to the output file. source_language     The language of the input text. If 'auto', Google Translate will attempt     to detect the language. target_language     The language to translate to. input_encoding     The encoding of the input file.</p> Source code in <code>src/rra_tools/translate.py</code> <pre><code>def translate_text_file(\n    input_path: str | Path,\n    output_path: str | Path,\n    source_language: str = \"auto\",\n    target_language: str = \"en\",\n    input_encoding: str = \"utf-8\",\n) -&gt; None:\n    \"\"\"Translate a text file line-by-line using Google Translate.\n\n    This function will produce a new file interleaving the original lines with\n    the translated lines. Google Translate is sometimes a little silly and so\n    having the original line next to the translated line can be helpful, especially\n    if you have some knowledge of the source language.\n\n    Parameters\n    ----------\n    input_path\n        The path to the input file.\n    output_path\n        The path to the output file.\n    source_language\n        The language of the input text. If 'auto', Google Translate will attempt\n        to detect the language.\n    target_language\n        The language to translate to.\n    input_encoding\n        The encoding of the input file.\n    \"\"\"\n    with Path(input_path, encoding=input_encoding).open() as f:\n        lines = f.readlines()\n\n    translator = GoogleTranslator(source=source_language, target=target_language)\n    translated_lines = translator.translate_batch(lines)\n\n    with Path(output_path).open(\"w\") as f:\n        for in_line, out_line in zip(lines, translated_lines, strict=False):\n            if in_line:\n                f.write(f\"{in_line.strip()}\\n{out_line.strip()}\\n\\n\")\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/","title":"cli_tools","text":""},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.convert_choice","title":"<code>convert_choice(value: str, choices: Collection[str]) -&gt; list[str]</code>","text":"<p>Convert a choice to a list of choices, handling the special 'All' choice.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.convert_choice--parameters","title":"Parameters","text":"<p>value     The choice to convert. choices     The set of choices to choose from.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.convert_choice--returns","title":"Returns","text":"<p>list[str]     The list of choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def convert_choice(value: str, choices: Collection[str]) -&gt; list[str]:\n    \"\"\"Convert a choice to a list of choices, handling the special 'All' choice.\n\n    Parameters\n    ----------\n    value\n        The choice to convert.\n    choices\n        The set of choices to choose from.\n\n    Returns\n    -------\n    list[str]\n        The list of choices.\n    \"\"\"\n    if value == RUN_ALL:\n        return list(choices)\n    elif value in choices:\n        return [value]\n    else:\n        msg = f\"Invalid choice: {value}. Must be one of {choices} or {RUN_ALL}.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.handle_exceptions","title":"<code>handle_exceptions(func: Callable[P, T], logger: SupportsLogging, *, with_debugger: bool) -&gt; Callable[P, T]</code>","text":"<p>Drops a user into an interactive debugger if func raises an error.</p> Source code in <code>src/rra_tools/cli_tools/exceptions.py</code> <pre><code>def handle_exceptions[**P, T](\n    func: Callable[P, T],\n    logger: SupportsLogging,\n    *,\n    with_debugger: bool,\n) -&gt; Callable[P, T]:\n    \"\"\"Drops a user into an interactive debugger if func raises an error.\"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; T:  # type: ignore[return]\n        try:\n            return func(*args, **kwargs)\n        except (BdbQuit, KeyboardInterrupt):\n            raise\n        except Exception:\n            msg = \"Uncaught exception\"\n            logger.exception(msg)\n            if with_debugger:\n                import pdb  # noqa: T100\n                import traceback\n\n                traceback.print_exc()\n                pdb.post_mortem()\n            else:\n                raise\n\n    return wrapped\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.import_module_from_info","title":"<code>import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType</code>","text":"<p>Import a module from a ModuleInfo object.</p> Source code in <code>src/rra_tools/cli_tools/importers.py</code> <pre><code>def import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType:\n    \"\"\"Import a module from a ModuleInfo object.\"\"\"\n    finder = module_info.module_finder\n    spec = finder.find_spec(module_info.name)  # type: ignore[call-arg]\n    module = spec.loader.load_module(module_info.name)  # type: ignore[union-attr]\n    return module  # noqa: RET504\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.process_choices","title":"<code>process_choices(allow_all: bool, choices: Collection[str] | None) -&gt; tuple[click.ParamType, str | None, bool]</code>","text":"<p>Support function for creating options with choices.</p> <p>A common pattern in RRA pipelines is to build CLIs that admit a choice of a specific set of values or a special value that represents all possible values. This function provides a way to handle this pattern in a consistent way.</p> <p>There are four possible cases: 1. No choices are provided and RUN_ALL is allowed. This is useful when the     set of choices is not known ahead of time, or is contingent on another     option. For example, if there is a task that depends on location and year,     but the years available depend on the location. The user might want to     run a single year for a location (which they'll have to know ahead of time);     or all years for a location, which would be the subset of years available     for that location; or all years for all locations, which could be a different     subset of years for each included location. 2. Choices are provided and RUN_ALL is allowed. This is useful when the set of     choices is known ahead of time, but the user might want to run all of them. 3. No choices are provided and RUN_ALL is not allowed. This is useful when the     set of choices is not known ahead of time, but the user must provide a value. 4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of     choices is known ahead of time and the user must provide a value.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.process_choices--parameters","title":"Parameters","text":"<p>allow_all     Whether to allow the special value RUN_ALL. choices     The set of choices to allow.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.process_choices--returns","title":"Returns","text":"<p>tuple[click.ParamType, str | None, bool]     The option type, default value, and whether to show the default.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def process_choices(\n    allow_all: bool,  # noqa: FBT001\n    choices: Collection[str] | None,\n) -&gt; tuple[click.ParamType, str | None, bool]:\n    \"\"\"Support function for creating options with choices.\n\n    A common pattern in RRA pipelines is to build CLIs that admit a choice\n    of a specific set of values or a special value that represents all\n    possible values. This function provides a way to handle this pattern\n    in a consistent way.\n\n    There are four possible cases:\n    1. No choices are provided and RUN_ALL is allowed. This is useful when the\n        set of choices is not known ahead of time, or is contingent on another\n        option. For example, if there is a task that depends on location and year,\n        but the years available depend on the location. The user might want to\n        run a single year for a location (which they'll have to know ahead of time);\n        or all years for a location, which would be the subset of years available\n        for that location; or all years for all locations, which could be a different\n        subset of years for each included location.\n    2. Choices are provided and RUN_ALL is allowed. This is useful when the set of\n        choices is known ahead of time, but the user might want to run all of them.\n    3. No choices are provided and RUN_ALL is not allowed. This is useful when the\n        set of choices is not known ahead of time, but the user must provide a value.\n    4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of\n        choices is known ahead of time and the user must provide a value.\n\n    Parameters\n    ----------\n    allow_all\n        Whether to allow the special value RUN_ALL.\n    choices\n        The set of choices to allow.\n\n    Returns\n    -------\n    tuple[click.ParamType, str | None, bool]\n        The option type, default value, and whether to show the default.\n    \"\"\"\n\n    if choices is None:\n        option_type: click.ParamType = click.STRING\n        default = RUN_ALL if allow_all else None\n    else:\n        choices = list(choices)\n        if allow_all:\n            choices.append(RUN_ALL)\n            default = RUN_ALL\n        else:\n            default = None\n        option_type = click.Choice(choices)\n    show_default = default is not None\n    return option_type, default, show_default\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.with_choice","title":"<code>with_choice(name: str, short_name: str | None = None, *, allow_all: bool = True, choices: Collection[str] | None = None, convert: bool | None = None, **kwargs: Any) -&gt; Callable[[Callable[P, T]], Callable[P, T]]</code>","text":"<p>Create an option with a set of choices.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.with_choice--parameters","title":"Parameters","text":"<p>name     The name of the option. short_name     An optional short name for the option. allow_all     Whether to allow the special value \"ALL\", which represents all choices. choices     The set of choices to allow. convert     Whether to convert the provided argument to a list, resolving the special     value \"ALL\" to all choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def with_choice[**P, T](\n    name: str,\n    short_name: str | None = None,\n    *,\n    allow_all: bool = True,\n    choices: Collection[str] | None = None,\n    convert: bool | None = None,\n    **kwargs: Any,\n) -&gt; Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create an option with a set of choices.\n\n    Parameters\n    ----------\n    name\n        The name of the option.\n    short_name\n        An optional short name for the option.\n    allow_all\n        Whether to allow the special value \"ALL\", which represents all choices.\n    choices\n        The set of choices to allow.\n    convert\n        Whether to convert the provided argument to a list, resolving the special\n        value \"ALL\" to all choices.\n\n    \"\"\"\n\n    names = [f\"--{name.replace('_', '-')}\"]\n    if short_name is not None:\n        if len(short_name) != 1:\n            msg = \"Short names must be a single character.\"\n            raise ValueError(msg)\n        names.append(f\"-{short_name}\")\n    option_type, default, show_default = process_choices(allow_all, choices)\n\n    if choices and convert is None:\n        convert = allow_all\n\n    if convert:\n        if not allow_all:\n            msg = \"Conversion is only supported when allow_all is True.\"\n            raise ValueError(msg)\n        if choices is None:\n            msg = \"Conversion is only supported when choices are provided.\"\n            raise ValueError(msg)\n\n        if \"callback\" in kwargs:\n            old_callback = kwargs.pop(\"callback\")\n\n            def _callback(\n                ctx: click.Context,\n                param: click.Parameter,\n                value: str,\n            ) -&gt; list[str]:\n                value = old_callback(ctx, param, value)\n                return convert_choice(value, choices)\n        else:\n\n            def _callback(\n                ctx: click.Context,  # noqa: ARG001\n                param: click.Parameter,  # noqa: ARG001\n                value: str,\n            ) -&gt; list[str]:\n                return convert_choice(value, choices)\n\n        kwargs[\"callback\"] = _callback\n\n    return click.option(\n        *names,\n        type=option_type,\n        default=default,\n        show_default=show_default,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.exceptions","title":"<code>exceptions</code>","text":""},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.exceptions.handle_exceptions","title":"<code>handle_exceptions(func: Callable[P, T], logger: SupportsLogging, *, with_debugger: bool) -&gt; Callable[P, T]</code>","text":"<p>Drops a user into an interactive debugger if func raises an error.</p> Source code in <code>src/rra_tools/cli_tools/exceptions.py</code> <pre><code>def handle_exceptions[**P, T](\n    func: Callable[P, T],\n    logger: SupportsLogging,\n    *,\n    with_debugger: bool,\n) -&gt; Callable[P, T]:\n    \"\"\"Drops a user into an interactive debugger if func raises an error.\"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; T:  # type: ignore[return]\n        try:\n            return func(*args, **kwargs)\n        except (BdbQuit, KeyboardInterrupt):\n            raise\n        except Exception:\n            msg = \"Uncaught exception\"\n            logger.exception(msg)\n            if with_debugger:\n                import pdb  # noqa: T100\n                import traceback\n\n                traceback.print_exc()\n                pdb.post_mortem()\n            else:\n                raise\n\n    return wrapped\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.importers","title":"<code>importers</code>","text":""},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.importers.import_module_from_info","title":"<code>import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType</code>","text":"<p>Import a module from a ModuleInfo object.</p> Source code in <code>src/rra_tools/cli_tools/importers.py</code> <pre><code>def import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType:\n    \"\"\"Import a module from a ModuleInfo object.\"\"\"\n    finder = module_info.module_finder\n    spec = finder.find_spec(module_info.name)  # type: ignore[call-arg]\n    module = spec.loader.load_module(module_info.name)  # type: ignore[union-attr]\n    return module  # noqa: RET504\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options","title":"<code>options</code>","text":""},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.convert_choice","title":"<code>convert_choice(value: str, choices: Collection[str]) -&gt; list[str]</code>","text":"<p>Convert a choice to a list of choices, handling the special 'All' choice.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.convert_choice--parameters","title":"Parameters","text":"<p>value     The choice to convert. choices     The set of choices to choose from.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.convert_choice--returns","title":"Returns","text":"<p>list[str]     The list of choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def convert_choice(value: str, choices: Collection[str]) -&gt; list[str]:\n    \"\"\"Convert a choice to a list of choices, handling the special 'All' choice.\n\n    Parameters\n    ----------\n    value\n        The choice to convert.\n    choices\n        The set of choices to choose from.\n\n    Returns\n    -------\n    list[str]\n        The list of choices.\n    \"\"\"\n    if value == RUN_ALL:\n        return list(choices)\n    elif value in choices:\n        return [value]\n    else:\n        msg = f\"Invalid choice: {value}. Must be one of {choices} or {RUN_ALL}.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.process_choices","title":"<code>process_choices(allow_all: bool, choices: Collection[str] | None) -&gt; tuple[click.ParamType, str | None, bool]</code>","text":"<p>Support function for creating options with choices.</p> <p>A common pattern in RRA pipelines is to build CLIs that admit a choice of a specific set of values or a special value that represents all possible values. This function provides a way to handle this pattern in a consistent way.</p> <p>There are four possible cases: 1. No choices are provided and RUN_ALL is allowed. This is useful when the     set of choices is not known ahead of time, or is contingent on another     option. For example, if there is a task that depends on location and year,     but the years available depend on the location. The user might want to     run a single year for a location (which they'll have to know ahead of time);     or all years for a location, which would be the subset of years available     for that location; or all years for all locations, which could be a different     subset of years for each included location. 2. Choices are provided and RUN_ALL is allowed. This is useful when the set of     choices is known ahead of time, but the user might want to run all of them. 3. No choices are provided and RUN_ALL is not allowed. This is useful when the     set of choices is not known ahead of time, but the user must provide a value. 4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of     choices is known ahead of time and the user must provide a value.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.process_choices--parameters","title":"Parameters","text":"<p>allow_all     Whether to allow the special value RUN_ALL. choices     The set of choices to allow.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.process_choices--returns","title":"Returns","text":"<p>tuple[click.ParamType, str | None, bool]     The option type, default value, and whether to show the default.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def process_choices(\n    allow_all: bool,  # noqa: FBT001\n    choices: Collection[str] | None,\n) -&gt; tuple[click.ParamType, str | None, bool]:\n    \"\"\"Support function for creating options with choices.\n\n    A common pattern in RRA pipelines is to build CLIs that admit a choice\n    of a specific set of values or a special value that represents all\n    possible values. This function provides a way to handle this pattern\n    in a consistent way.\n\n    There are four possible cases:\n    1. No choices are provided and RUN_ALL is allowed. This is useful when the\n        set of choices is not known ahead of time, or is contingent on another\n        option. For example, if there is a task that depends on location and year,\n        but the years available depend on the location. The user might want to\n        run a single year for a location (which they'll have to know ahead of time);\n        or all years for a location, which would be the subset of years available\n        for that location; or all years for all locations, which could be a different\n        subset of years for each included location.\n    2. Choices are provided and RUN_ALL is allowed. This is useful when the set of\n        choices is known ahead of time, but the user might want to run all of them.\n    3. No choices are provided and RUN_ALL is not allowed. This is useful when the\n        set of choices is not known ahead of time, but the user must provide a value.\n    4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of\n        choices is known ahead of time and the user must provide a value.\n\n    Parameters\n    ----------\n    allow_all\n        Whether to allow the special value RUN_ALL.\n    choices\n        The set of choices to allow.\n\n    Returns\n    -------\n    tuple[click.ParamType, str | None, bool]\n        The option type, default value, and whether to show the default.\n    \"\"\"\n\n    if choices is None:\n        option_type: click.ParamType = click.STRING\n        default = RUN_ALL if allow_all else None\n    else:\n        choices = list(choices)\n        if allow_all:\n            choices.append(RUN_ALL)\n            default = RUN_ALL\n        else:\n            default = None\n        option_type = click.Choice(choices)\n    show_default = default is not None\n    return option_type, default, show_default\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.with_choice","title":"<code>with_choice(name: str, short_name: str | None = None, *, allow_all: bool = True, choices: Collection[str] | None = None, convert: bool | None = None, **kwargs: Any) -&gt; Callable[[Callable[P, T]], Callable[P, T]]</code>","text":"<p>Create an option with a set of choices.</p>"},{"location":"reference/rra_tools/cli_tools/#rra_tools.cli_tools.options.with_choice--parameters","title":"Parameters","text":"<p>name     The name of the option. short_name     An optional short name for the option. allow_all     Whether to allow the special value \"ALL\", which represents all choices. choices     The set of choices to allow. convert     Whether to convert the provided argument to a list, resolving the special     value \"ALL\" to all choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def with_choice[**P, T](\n    name: str,\n    short_name: str | None = None,\n    *,\n    allow_all: bool = True,\n    choices: Collection[str] | None = None,\n    convert: bool | None = None,\n    **kwargs: Any,\n) -&gt; Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create an option with a set of choices.\n\n    Parameters\n    ----------\n    name\n        The name of the option.\n    short_name\n        An optional short name for the option.\n    allow_all\n        Whether to allow the special value \"ALL\", which represents all choices.\n    choices\n        The set of choices to allow.\n    convert\n        Whether to convert the provided argument to a list, resolving the special\n        value \"ALL\" to all choices.\n\n    \"\"\"\n\n    names = [f\"--{name.replace('_', '-')}\"]\n    if short_name is not None:\n        if len(short_name) != 1:\n            msg = \"Short names must be a single character.\"\n            raise ValueError(msg)\n        names.append(f\"-{short_name}\")\n    option_type, default, show_default = process_choices(allow_all, choices)\n\n    if choices and convert is None:\n        convert = allow_all\n\n    if convert:\n        if not allow_all:\n            msg = \"Conversion is only supported when allow_all is True.\"\n            raise ValueError(msg)\n        if choices is None:\n            msg = \"Conversion is only supported when choices are provided.\"\n            raise ValueError(msg)\n\n        if \"callback\" in kwargs:\n            old_callback = kwargs.pop(\"callback\")\n\n            def _callback(\n                ctx: click.Context,\n                param: click.Parameter,\n                value: str,\n            ) -&gt; list[str]:\n                value = old_callback(ctx, param, value)\n                return convert_choice(value, choices)\n        else:\n\n            def _callback(\n                ctx: click.Context,  # noqa: ARG001\n                param: click.Parameter,  # noqa: ARG001\n                value: str,\n            ) -&gt; list[str]:\n                return convert_choice(value, choices)\n\n        kwargs[\"callback\"] = _callback\n\n    return click.option(\n        *names,\n        type=option_type,\n        default=default,\n        show_default=show_default,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/exceptions/","title":"exceptions","text":""},{"location":"reference/rra_tools/cli_tools/exceptions/#rra_tools.cli_tools.exceptions.handle_exceptions","title":"<code>handle_exceptions(func: Callable[P, T], logger: SupportsLogging, *, with_debugger: bool) -&gt; Callable[P, T]</code>","text":"<p>Drops a user into an interactive debugger if func raises an error.</p> Source code in <code>src/rra_tools/cli_tools/exceptions.py</code> <pre><code>def handle_exceptions[**P, T](\n    func: Callable[P, T],\n    logger: SupportsLogging,\n    *,\n    with_debugger: bool,\n) -&gt; Callable[P, T]:\n    \"\"\"Drops a user into an interactive debugger if func raises an error.\"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; T:  # type: ignore[return]\n        try:\n            return func(*args, **kwargs)\n        except (BdbQuit, KeyboardInterrupt):\n            raise\n        except Exception:\n            msg = \"Uncaught exception\"\n            logger.exception(msg)\n            if with_debugger:\n                import pdb  # noqa: T100\n                import traceback\n\n                traceback.print_exc()\n                pdb.post_mortem()\n            else:\n                raise\n\n    return wrapped\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/importers/","title":"importers","text":""},{"location":"reference/rra_tools/cli_tools/importers/#rra_tools.cli_tools.importers.import_module_from_info","title":"<code>import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType</code>","text":"<p>Import a module from a ModuleInfo object.</p> Source code in <code>src/rra_tools/cli_tools/importers.py</code> <pre><code>def import_module_from_info(module_info: ModuleInfo) -&gt; ModuleType:\n    \"\"\"Import a module from a ModuleInfo object.\"\"\"\n    finder = module_info.module_finder\n    spec = finder.find_spec(module_info.name)  # type: ignore[call-arg]\n    module = spec.loader.load_module(module_info.name)  # type: ignore[union-attr]\n    return module  # noqa: RET504\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/options/","title":"options","text":""},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.convert_choice","title":"<code>convert_choice(value: str, choices: Collection[str]) -&gt; list[str]</code>","text":"<p>Convert a choice to a list of choices, handling the special 'All' choice.</p>"},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.convert_choice--parameters","title":"Parameters","text":"<p>value     The choice to convert. choices     The set of choices to choose from.</p>"},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.convert_choice--returns","title":"Returns","text":"<p>list[str]     The list of choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def convert_choice(value: str, choices: Collection[str]) -&gt; list[str]:\n    \"\"\"Convert a choice to a list of choices, handling the special 'All' choice.\n\n    Parameters\n    ----------\n    value\n        The choice to convert.\n    choices\n        The set of choices to choose from.\n\n    Returns\n    -------\n    list[str]\n        The list of choices.\n    \"\"\"\n    if value == RUN_ALL:\n        return list(choices)\n    elif value in choices:\n        return [value]\n    else:\n        msg = f\"Invalid choice: {value}. Must be one of {choices} or {RUN_ALL}.\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.process_choices","title":"<code>process_choices(allow_all: bool, choices: Collection[str] | None) -&gt; tuple[click.ParamType, str | None, bool]</code>","text":"<p>Support function for creating options with choices.</p> <p>A common pattern in RRA pipelines is to build CLIs that admit a choice of a specific set of values or a special value that represents all possible values. This function provides a way to handle this pattern in a consistent way.</p> <p>There are four possible cases: 1. No choices are provided and RUN_ALL is allowed. This is useful when the     set of choices is not known ahead of time, or is contingent on another     option. For example, if there is a task that depends on location and year,     but the years available depend on the location. The user might want to     run a single year for a location (which they'll have to know ahead of time);     or all years for a location, which would be the subset of years available     for that location; or all years for all locations, which could be a different     subset of years for each included location. 2. Choices are provided and RUN_ALL is allowed. This is useful when the set of     choices is known ahead of time, but the user might want to run all of them. 3. No choices are provided and RUN_ALL is not allowed. This is useful when the     set of choices is not known ahead of time, but the user must provide a value. 4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of     choices is known ahead of time and the user must provide a value.</p>"},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.process_choices--parameters","title":"Parameters","text":"<p>allow_all     Whether to allow the special value RUN_ALL. choices     The set of choices to allow.</p>"},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.process_choices--returns","title":"Returns","text":"<p>tuple[click.ParamType, str | None, bool]     The option type, default value, and whether to show the default.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def process_choices(\n    allow_all: bool,  # noqa: FBT001\n    choices: Collection[str] | None,\n) -&gt; tuple[click.ParamType, str | None, bool]:\n    \"\"\"Support function for creating options with choices.\n\n    A common pattern in RRA pipelines is to build CLIs that admit a choice\n    of a specific set of values or a special value that represents all\n    possible values. This function provides a way to handle this pattern\n    in a consistent way.\n\n    There are four possible cases:\n    1. No choices are provided and RUN_ALL is allowed. This is useful when the\n        set of choices is not known ahead of time, or is contingent on another\n        option. For example, if there is a task that depends on location and year,\n        but the years available depend on the location. The user might want to\n        run a single year for a location (which they'll have to know ahead of time);\n        or all years for a location, which would be the subset of years available\n        for that location; or all years for all locations, which could be a different\n        subset of years for each included location.\n    2. Choices are provided and RUN_ALL is allowed. This is useful when the set of\n        choices is known ahead of time, but the user might want to run all of them.\n    3. No choices are provided and RUN_ALL is not allowed. This is useful when the\n        set of choices is not known ahead of time, but the user must provide a value.\n    4. Choices are provided and RUN_ALL is not allowed. This is useful when the set of\n        choices is known ahead of time and the user must provide a value.\n\n    Parameters\n    ----------\n    allow_all\n        Whether to allow the special value RUN_ALL.\n    choices\n        The set of choices to allow.\n\n    Returns\n    -------\n    tuple[click.ParamType, str | None, bool]\n        The option type, default value, and whether to show the default.\n    \"\"\"\n\n    if choices is None:\n        option_type: click.ParamType = click.STRING\n        default = RUN_ALL if allow_all else None\n    else:\n        choices = list(choices)\n        if allow_all:\n            choices.append(RUN_ALL)\n            default = RUN_ALL\n        else:\n            default = None\n        option_type = click.Choice(choices)\n    show_default = default is not None\n    return option_type, default, show_default\n</code></pre>"},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.with_choice","title":"<code>with_choice(name: str, short_name: str | None = None, *, allow_all: bool = True, choices: Collection[str] | None = None, convert: bool | None = None, **kwargs: Any) -&gt; Callable[[Callable[P, T]], Callable[P, T]]</code>","text":"<p>Create an option with a set of choices.</p>"},{"location":"reference/rra_tools/cli_tools/options/#rra_tools.cli_tools.options.with_choice--parameters","title":"Parameters","text":"<p>name     The name of the option. short_name     An optional short name for the option. allow_all     Whether to allow the special value \"ALL\", which represents all choices. choices     The set of choices to allow. convert     Whether to convert the provided argument to a list, resolving the special     value \"ALL\" to all choices.</p> Source code in <code>src/rra_tools/cli_tools/options.py</code> <pre><code>def with_choice[**P, T](\n    name: str,\n    short_name: str | None = None,\n    *,\n    allow_all: bool = True,\n    choices: Collection[str] | None = None,\n    convert: bool | None = None,\n    **kwargs: Any,\n) -&gt; Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create an option with a set of choices.\n\n    Parameters\n    ----------\n    name\n        The name of the option.\n    short_name\n        An optional short name for the option.\n    allow_all\n        Whether to allow the special value \"ALL\", which represents all choices.\n    choices\n        The set of choices to allow.\n    convert\n        Whether to convert the provided argument to a list, resolving the special\n        value \"ALL\" to all choices.\n\n    \"\"\"\n\n    names = [f\"--{name.replace('_', '-')}\"]\n    if short_name is not None:\n        if len(short_name) != 1:\n            msg = \"Short names must be a single character.\"\n            raise ValueError(msg)\n        names.append(f\"-{short_name}\")\n    option_type, default, show_default = process_choices(allow_all, choices)\n\n    if choices and convert is None:\n        convert = allow_all\n\n    if convert:\n        if not allow_all:\n            msg = \"Conversion is only supported when allow_all is True.\"\n            raise ValueError(msg)\n        if choices is None:\n            msg = \"Conversion is only supported when choices are provided.\"\n            raise ValueError(msg)\n\n        if \"callback\" in kwargs:\n            old_callback = kwargs.pop(\"callback\")\n\n            def _callback(\n                ctx: click.Context,\n                param: click.Parameter,\n                value: str,\n            ) -&gt; list[str]:\n                value = old_callback(ctx, param, value)\n                return convert_choice(value, choices)\n        else:\n\n            def _callback(\n                ctx: click.Context,  # noqa: ARG001\n                param: click.Parameter,  # noqa: ARG001\n                value: str,\n            ) -&gt; list[str]:\n                return convert_choice(value, choices)\n\n        kwargs[\"callback\"] = _callback\n\n    return click.option(\n        *names,\n        type=option_type,\n        default=default,\n        show_default=show_default,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/rra_tools/logging/","title":"logging","text":""},{"location":"reference/rra_tools/logging/#rra_tools.logging.add_logging_sink","title":"<code>add_logging_sink(sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path, verbose: int, *, colorize: bool = False, serialize: bool = False) -&gt; None</code>","text":"<p>Add a new output file handle for logging.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def add_logging_sink(\n    sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path,\n    verbose: int,\n    *,\n    colorize: bool = False,\n    serialize: bool = False,\n) -&gt; None:\n    \"\"\"Add a new output file handle for logging.\"\"\"\n    level, message_format = LOG_FORMATS.get(\n        verbose, LOG_FORMATS[max(LOG_FORMATS.keys())]\n    )\n    logger.add(\n        sink,  # type: ignore[arg-type]\n        colorize=colorize,\n        level=level,\n        format=message_format,\n        serialize=serialize,\n        filter={\n            # Suppress logs up to the level provided.\n            \"urllib3\": \"WARNING\",  # Uselessly (for us) noisy.\n        },\n    )\n</code></pre>"},{"location":"reference/rra_tools/logging/#rra_tools.logging.configure_logging_to_files","title":"<code>configure_logging_to_files(log_dir: str | Path) -&gt; None</code>","text":"<p>Sets up logging to a file in an output directory.</p> <p>Logs to files are done with the highest verbosity to allow for debugging if necessary.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_files(log_dir: str | Path) -&gt; None:\n    \"\"\"Sets up logging to a file in an output directory.\n\n    Logs to files are done with the highest verbosity to allow\n    for debugging if necessary.\n\n    \"\"\"\n    mkdir(log_dir, exist_ok=True)\n    add_logging_sink(\n        Path(log_dir) / \"main_log.json\",\n        verbose=3,\n        serialize=True,\n    )\n    add_logging_sink(\n        Path(log_dir) / \"main_log.txt\",\n        verbose=3,\n    )\n</code></pre>"},{"location":"reference/rra_tools/logging/#rra_tools.logging.configure_logging_to_terminal","title":"<code>configure_logging_to_terminal(verbose: int) -&gt; None</code>","text":"<p>Setup logging to sys.stdout.</p> <p>This is presumed to be one of the first calls made in an application entry point. Any logging that occurs before this call won't be intercepted or handled with the standard logging configuration.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_terminal(verbose: int) -&gt; None:\n    \"\"\"Setup logging to sys.stdout.\n\n    This is presumed to be one of the first calls made in an\n    application entry point. Any logging that occurs before this\n    call won't be intercepted or handled with the standard\n    logging configuration.\n\n    \"\"\"\n    logger.remove(0)  # Clear default configuration\n    add_logging_sink(sys.stdout, verbose, colorize=True)\n</code></pre>"},{"location":"reference/rra_tools/logging/#rra_tools.logging.config","title":"<code>config</code>","text":""},{"location":"reference/rra_tools/logging/#rra_tools.logging.config.add_logging_sink","title":"<code>add_logging_sink(sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path, verbose: int, *, colorize: bool = False, serialize: bool = False) -&gt; None</code>","text":"<p>Add a new output file handle for logging.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def add_logging_sink(\n    sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path,\n    verbose: int,\n    *,\n    colorize: bool = False,\n    serialize: bool = False,\n) -&gt; None:\n    \"\"\"Add a new output file handle for logging.\"\"\"\n    level, message_format = LOG_FORMATS.get(\n        verbose, LOG_FORMATS[max(LOG_FORMATS.keys())]\n    )\n    logger.add(\n        sink,  # type: ignore[arg-type]\n        colorize=colorize,\n        level=level,\n        format=message_format,\n        serialize=serialize,\n        filter={\n            # Suppress logs up to the level provided.\n            \"urllib3\": \"WARNING\",  # Uselessly (for us) noisy.\n        },\n    )\n</code></pre>"},{"location":"reference/rra_tools/logging/#rra_tools.logging.config.configure_logging_to_files","title":"<code>configure_logging_to_files(log_dir: str | Path) -&gt; None</code>","text":"<p>Sets up logging to a file in an output directory.</p> <p>Logs to files are done with the highest verbosity to allow for debugging if necessary.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_files(log_dir: str | Path) -&gt; None:\n    \"\"\"Sets up logging to a file in an output directory.\n\n    Logs to files are done with the highest verbosity to allow\n    for debugging if necessary.\n\n    \"\"\"\n    mkdir(log_dir, exist_ok=True)\n    add_logging_sink(\n        Path(log_dir) / \"main_log.json\",\n        verbose=3,\n        serialize=True,\n    )\n    add_logging_sink(\n        Path(log_dir) / \"main_log.txt\",\n        verbose=3,\n    )\n</code></pre>"},{"location":"reference/rra_tools/logging/#rra_tools.logging.config.configure_logging_to_terminal","title":"<code>configure_logging_to_terminal(verbose: int) -&gt; None</code>","text":"<p>Setup logging to sys.stdout.</p> <p>This is presumed to be one of the first calls made in an application entry point. Any logging that occurs before this call won't be intercepted or handled with the standard logging configuration.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_terminal(verbose: int) -&gt; None:\n    \"\"\"Setup logging to sys.stdout.\n\n    This is presumed to be one of the first calls made in an\n    application entry point. Any logging that occurs before this\n    call won't be intercepted or handled with the standard\n    logging configuration.\n\n    \"\"\"\n    logger.remove(0)  # Clear default configuration\n    add_logging_sink(sys.stdout, verbose, colorize=True)\n</code></pre>"},{"location":"reference/rra_tools/logging/config/","title":"config","text":""},{"location":"reference/rra_tools/logging/config/#rra_tools.logging.config.add_logging_sink","title":"<code>add_logging_sink(sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path, verbose: int, *, colorize: bool = False, serialize: bool = False) -&gt; None</code>","text":"<p>Add a new output file handle for logging.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def add_logging_sink(\n    sink: TextIO | loguru.Writable | Callable[[loguru.Message], None] | Handler | Path,\n    verbose: int,\n    *,\n    colorize: bool = False,\n    serialize: bool = False,\n) -&gt; None:\n    \"\"\"Add a new output file handle for logging.\"\"\"\n    level, message_format = LOG_FORMATS.get(\n        verbose, LOG_FORMATS[max(LOG_FORMATS.keys())]\n    )\n    logger.add(\n        sink,  # type: ignore[arg-type]\n        colorize=colorize,\n        level=level,\n        format=message_format,\n        serialize=serialize,\n        filter={\n            # Suppress logs up to the level provided.\n            \"urllib3\": \"WARNING\",  # Uselessly (for us) noisy.\n        },\n    )\n</code></pre>"},{"location":"reference/rra_tools/logging/config/#rra_tools.logging.config.configure_logging_to_files","title":"<code>configure_logging_to_files(log_dir: str | Path) -&gt; None</code>","text":"<p>Sets up logging to a file in an output directory.</p> <p>Logs to files are done with the highest verbosity to allow for debugging if necessary.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_files(log_dir: str | Path) -&gt; None:\n    \"\"\"Sets up logging to a file in an output directory.\n\n    Logs to files are done with the highest verbosity to allow\n    for debugging if necessary.\n\n    \"\"\"\n    mkdir(log_dir, exist_ok=True)\n    add_logging_sink(\n        Path(log_dir) / \"main_log.json\",\n        verbose=3,\n        serialize=True,\n    )\n    add_logging_sink(\n        Path(log_dir) / \"main_log.txt\",\n        verbose=3,\n    )\n</code></pre>"},{"location":"reference/rra_tools/logging/config/#rra_tools.logging.config.configure_logging_to_terminal","title":"<code>configure_logging_to_terminal(verbose: int) -&gt; None</code>","text":"<p>Setup logging to sys.stdout.</p> <p>This is presumed to be one of the first calls made in an application entry point. Any logging that occurs before this call won't be intercepted or handled with the standard logging configuration.</p> Source code in <code>src/rra_tools/logging/config.py</code> <pre><code>def configure_logging_to_terminal(verbose: int) -&gt; None:\n    \"\"\"Setup logging to sys.stdout.\n\n    This is presumed to be one of the first calls made in an\n    application entry point. Any logging that occurs before this\n    call won't be intercepted or handled with the standard\n    logging configuration.\n\n    \"\"\"\n    logger.remove(0)  # Clear default configuration\n    add_logging_sink(sys.stdout, verbose, colorize=True)\n</code></pre>"},{"location":"reference/rra_tools/logging/performance/","title":"performance","text":""},{"location":"reference/rra_tools/logging/protocol/","title":"protocol","text":""}]}